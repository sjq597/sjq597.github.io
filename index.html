<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"sjq597.github.io","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.18.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="数据开发工程师的成长历程">
<meta property="og:type" content="website">
<meta property="og:title" content="LittleQ">
<meta property="og:url" content="http://sjq597.github.io/index.html">
<meta property="og:site_name" content="LittleQ">
<meta property="og:description" content="数据开发工程师的成长历程">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="LittleQ">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://sjq597.github.io/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>LittleQ</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">LittleQ</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">爱好：写代码</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">LittleQ</p>
  <div class="site-description" itemprop="description">数据开发工程师的成长历程</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">145</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">51</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://sjq597.github.io/2020/05/18/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E%E4%B9%8B-Spark-Streaming%E7%81%8C%E6%B0%B4%E7%AF%87/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LittleQ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LittleQ">
      <meta itemprop="description" content="数据开发工程师的成长历程">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LittleQ">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/05/18/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E%E4%B9%8B-Spark-Streaming%E7%81%8C%E6%B0%B4%E7%AF%87/" class="post-title-link" itemprop="url">流式计算引擎之-Spark Streaming灌水篇</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-05-18 22:44:52" itemprop="dateCreated datePublished" datetime="2020-05-18T22:44:52+08:00">2020-05-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-10-07 14:54:54" itemprop="dateModified" datetime="2023-10-07T14:54:54+08:00">2023-10-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E6%9E%B6%E6%9E%84/" itemprop="url" rel="index"><span itemprop="name">数据架构</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.4k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>12 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="废话"><a href="#废话" class="headerlink" title="废话"></a>废话</h3><p>一直想写一篇关于<code>Spark Streaming</code>的文章，但是实在是事情太多，当然主要还是我比较懒，身边的同事已经明示我博客好久都不更新来催更了，技术都快荒废了，所以先水一篇。这篇文章虽然是叫灌水篇，但实际上都是我在实际项目中学习和总结到的一些切身经验，如果你真的想在生产环境去用Spark Streaming实现一些简单的实时计算或者实时监控，看板之类的，有一些问题是你一开始就得考虑到的，并且得有非常可靠的解决方案。</p>
<p>算起来差不多有快两年没用过<code>Spark Streaming</code>了，毕竟现在的公司也是主推<code>Flink</code>了，从趋势来看，的确是<code>Flink</code>的势头更猛一些，虽说<code>Spark Streaming</code>后来引入<code>Structed Streaming</code>，据说性能提升不少,这个我也没用过，暂时就不做深入讨论了。</p>
<p>其实这个系列计划后面还有一篇<code>JStorm</code>，一篇<code>Flink</code>，之所以把<code>Spark Streaming</code>放在第一篇来讲主要是有两个原因：首先是这个框架算是在实际做项目中钻研过一段时间，对其使用中的坑也算踩了不少，最后也算圆满完成了项目；其次是之前在招人的时候面试过很多人，简历上写了做过的一些<code>Spark Streaming</code>项目，在考察他们项目的时候，问的深了慢慢就懵了，从来没有碰到过一个人有认真思考过那些问题，当然这里面有很多人的简历大概率是培训机构的一些模板(数仓分层 + Spark Streaming + 用户画像，基本是这个结构，技术选型一模一样,另外也吐槽下那些培训机构，你告诉别人用户画像放在<code>HBase</code>这没啥问题，问题是你总得好好讲下<code>rowkey</code>这个吧，连怎么设计，为什么要这么设计也不讲讲，一问就完蛋)，本身也没真正做过<code>Spark Streaming</code>的项目，对框架的一些设计理念和底层的东西更加没有了解过。</p>
<h3 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h3><p>所以这篇文章主要会说一下一些实际项目中比较关注的问题，这些问题大概率也是面试官比较喜欢问的，做实时计算的确也绕不开那几个问题,好久没用了，想到什么写什么，截图是肯定没有了,但是如果你看到这篇文章，又或者在找解决方案，我想没有图应该也看得懂,下面就讲几个比较重要的问题。</p>
<h4 id="Spark-Streaming会丢数据吗"><a href="#Spark-Streaming会丢数据吗" class="headerlink" title="Spark Streaming会丢数据吗"></a>Spark Streaming会丢数据吗</h4><p>相信每个做实时计算的人都会碰到这个问题，或者说被别人追问过这个问题:为什么我从xxx能查到数据，从你实时处理之后就查不到了?又或者是这段时间的指标看着好像有问题，线上实时计算程序没漏掉数据吧？如果你非常自信的告诉别人，不可能丢的，这个<code>Spark Streaming</code>官网说了，xxx和xxx机制可以保证即使程序挂了，也能恢复，数据不会丢的。但是实际情况会比较复杂，很可能会被立马打脸，或者说运气好，丢了一两条也没人看的出来，但是其实有一些项目是连一条数据都不能丢的。</p>
<p>这里先说下结论，其实<code>Spark Streaming</code>是会丢数据的，要想保证数据100%不丢失，你需要根据实际情况，也就是输入输出的存储系统来做很多的处理，否则，丢数据的情况会有很多种，丢不丢数取决于你的集群和系统的稳定性。</p>
<p>所以每次碰到简历上写着<code>Spark Streaming</code>项目的人，我的第一个问题就是：你这个程序会丢数据吗？他们一开始都会很确定的告诉我不会，并且会开始讲自己是通过<code>Direct</code>的方式去消费<code>Kafka</code>的数据，手动维护<code>offset</code>的，只有当数据处理成功了才会提交offset,所以即使程序挂了，重启之后还是会从之前的offset开始消费，数据不会丢。当然有时候也会顺带问下他们<code>Receiver</code>模式和<code>Direct</code>的区别和为什么选后者，算是比较基本的问题，但是有的培训机构居然连这个也没讲明白。很多人都认为是不能手动维护<code>offset</code>，所以有丢数的风险,其实主要原因并不是这个，这里就不展开讲了。</p>
<p>但是我们面临的实际问题是，手动维护<code>offset</code>,确保每次处理成功了才提交<code>offset</code>就真的不会丢数据吗？从表面上来看，这个想法确实没什么问题，但是如果你对<code>Spark Sgreaming</code>了解的够深，就会发现这个想法是错的。其实要想知道会不会丢数，就得稍微了解一下底层的东西，或者说多看看监控和SparkUI界面的信息，了解一下<code>Application</code>,<code>Job</code>,<code>Task</code>,<code>Batch</code>这些概念，如果你把这几个东西搞清楚了，我相信你应该可以大致判断出来你写的程序是否有丢数据的风险以及在什么情况下会丢数据。</p>
<h5 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h5><p>正式讲问题之前，先得看几个基本概念</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>Application</td>
<td>应用程序，也就是你每次提交一个Spark Streaming任务的时候，运行在集群上的一个计算任务</td>
</tr>
<tr>
<td>Batch</td>
<td><code>Spark Streaming</code>核心理念就是<code>micro batch</code>也就是算子和程序并不是时时刻刻都在计算和处理数据的，而是每隔一段时间成成一个批次</td>
</tr>
<tr>
<td>Job</td>
<td>一个计算任务可能会包含多个Job,大部分应该就是一个</td>
</tr>
<tr>
<td>Task</td>
<td>任务最终执行计算最小单位，对于<code>source</code>是<code>kafka</code>的情况，总的数量一般和需要消费的分区数相等，最大同时执行<code>task</code>个数可以通过一些参数来设置</td>
</tr>
</tbody></table>
<p>所以其实是每次开始调度执行一个Batch，会生成job，然后job会分stage,最细粒度就是到task执行具体的逻辑。因为我写<code>Spark Streaming</code>程序中也没见过有两个job的，所以暂且以只有一个job的程序为例，讨论下什么场景下会丢数据以及深层次的原因，下面主要介绍下<code>Task</code>和<code>Batch</code>：</p>
<ol>
<li>Task<br>作为最终消费和处理数据的执行单元，也就是你程序里面真正处理数据的算子和最终的<code>action</code>操作，对于手动维护<code>offset</code>来说，一般就是在所有数据处理完，就调用Kafka的api来<code>commit offset</code>，这样就确保了如果程序出现异常情况挂掉，<code>offset</code>不会更新，当程序再次重启，会从zk上读取消费的信息，从上一次最后提交的<code>offset</code>后开始消费数据。这也就是大家普遍认为不会丢数的依据;</li>
<li>Batch<br>一般会在程序中设置批次的间隔，也就是多长时间生成一个批次，这个取决于实际场景，假设是5min一个批次，所以每隔5分钟程序会自动生成新的批次，然后根据资源情况和上一个批次的执行情况来决定是否开始调度此批次。需要说明下，大部分情况，也就是默认情况下，同时执行的批次只能是一个，也就是如果数据太多导致上一个批次没有执行完，后面生成的批次就会被pending住。并且默认的调度算法是FIFO，所以基本上就是按数据的消费顺序来处理数据;</li>
<li>异常<br>可以看到其实整个<code>Spark Streaming</code>程序从表格上来看，从上到下是一个任务的逐渐细化过程，所以问题来了，计算任务失败是如何定义的,<code>Task</code>失败了<code>Job</code>会失败吗？<code>Batch</code>会失败吗？<code>Application</code>会失败吗？</li>
</ol>
<ul>
<li>Task会有默认的重试次数，好像是4次，可能不同的平台会额外设置，这个参数是可以设置的。Task执行失败了会自动重试，如果超过了最大重试次数还是执行失败，那这个Task所在的Job就失败了,所以当前批次的状态就是<code>Failed</code>；</li>
<li>Job失败了就失败了，因为Task已经重试过了仍然失败，最终这个<code>Batch</code>失败了, 但是<code>Application</code>并不会失败，一般而言，Task重试了很多次，会耗费很多时间，所以会有pending状态的Batch，这个时候其实会直接调用下一个pending的批次继续执行。</li>
</ul>
<h5 id="案例分析"><a href="#案例分析" class="headerlink" title="案例分析"></a>案例分析</h5><p>所以到这里你就应该明白了为什么说，即使你使用直连方式消费kafka，手动维护offset,仍然会丢数据。这里还需要再额外讲一下，每个批次在生成之前，就会计算出这个批次当前需要消费的数据范围，也就是[offset1,offset2]这种，对应到kafka的每个分区，哪怕你上一个batch还没执行完，下一个批次他会算出他此时需要消费的数据。至于怎么算的，有时间后面展开说，总之不是每次开始执行才去zk里面读取最新offset开始消费，这里记住就行了，因为和丢数有关。</p>
<p>上面讲到了每个批次要处理的数据其实是根据以往任务执行的情况来估算出来的，假设第一个批次在执行过程中由于在不停的重试，时间超过了一个批次，后面又生成了几个批次，并且由于同时最多只能有一个batch在执行，其他的都在pending状态。这个时候当Task的失败重试次数超过了设置的最大失败重试次数，即最终还是失败了，于是第一个批次就挂了。并且由于程序设置的是执行成功之后才会commit offset,导致偏移量也没有提交，到此为止还算正常毕竟虽然失败了，但是offset也没有更新，如果重启的话，还是会从上一次成功的地方接着消费。</p>
<p>但事实是紧接着由于第一个批次失败了，资源空闲出来了，后面pending的第一个批次就开始调度了，然后呢比较顺利，马上就执行成功了，这个时候程序触发了<code>commit offset</code>,将最新的消费情况更新到了zk。依次类推，后面的批次按照之前算好的消息范围继续消费，成功后<code>commit offset</code>。于是在执行成功了几个批次之后，突然发现，第一个批次失败了，offset被第二个和后面的批次更新覆盖了，然而实际上消息并没有被消费处理，因为第二个批次处理的消息是提前算好的，这就是数据丢失的真实场景。</p>
<h5 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h5><p>要怎么做才可以保证数据不丢失呢？其实通过上面的分析，会导致丢数据的根本原因其实是因为Batch失败了，但是Application并没有失败，后续执行的Batch成功了把offset给覆盖了。所以解决问题的方法其实有两种:</p>
<ol>
<li>不让Batch失败，这样就不会存在前面的批次失败了，后面的批次成功了这种情况。但是实际情况下总会存在程序出异常的情况，所以可以在程序出问题的时候将程序hang住，比如将Task的最大失败重试次数设置成int最大值。不过这样也有问题，一是如果就是程序的确就有问题，重试也不会成功，白白重试浪费资源；另外就是如果程序计算很快，那么重试也会有试完的时候，然后开始调度下一个<code>Batch</code>，所以并不推荐这种方式；</li>
<li><code>Batch</code>失败了让<code>Application</code>也失败，根本原因其实是<code>Batch</code>失败了<code>Application</code>没有失败，继续调度后续<code>Batch</code>导致<code>offset</code>被覆盖。这里需要借助因为第二个批次处理的消息是提前算好的，</li>
</ol>
<p>这里需要借助下<code>StreamingListener</code>这个类，你需要继承这个接口，来监听Job的执行状态，从而来控制当Job失败了，程序直接重启，不要直接调度下一个<code>Batch</code>。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Batch</span> <span class="keyword">extends</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">  <span class="keyword">var</span> failedCnt: <span class="type">Long</span> = <span class="number">0</span></span><br><span class="line">  <span class="keyword">var</span> successCnt: <span class="type">Long</span> = <span class="number">0</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BasedataSparkBatchListener</span>(<span class="params">ssc: <span class="type">StreamingContext</span></span>) <span class="keyword">extends</span> <span class="title">StreamingListener</span> </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> batch = <span class="keyword">new</span> <span class="type">Batch</span>()</span><br><span class="line">  <span class="comment">/** Called when a batch of jobs has been submitted for processing. */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">onBatchSubmitted</span></span>(batchSubmitted: <span class="type">StreamingListenerBatchSubmitted</span>) &#123; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Called when processing of a batch of jobs has started.  */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">onBatchStarted</span></span>(batchStarted: <span class="type">StreamingListenerBatchStarted</span>) &#123; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Called when processing of a batch of jobs has completed. */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">onBatchCompleted</span></span>(batchCompleted: <span class="type">StreamingListenerBatchCompleted</span>) &#123; </span><br><span class="line">   <span class="keyword">val</span> batchInfo = batchCompleted.batchInfo</span><br><span class="line">    <span class="keyword">val</span> outputOperations = batchInfo.outputOperationInfos</span><br><span class="line">    <span class="keyword">val</span> numFailedOutputOp = outputOperations.values.count(_.failureReason.nonEmpty)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">if</span> (numFailedOutputOp != <span class="number">0</span>) &#123;</span><br><span class="line">      batch.failedCnt += <span class="number">1</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      batch.failedCnt += <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>可以看到有很多方法，这里其实只需要实现<code>onBatchCompleted</code>方法获取失败的Batch数量就行,然后主程序需要注册下这个<code>listener</code>:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val listener = new BasedataSparkBatchListener(ssc)</span><br><span class="line">ssc.addStreamingListener(listener)</span><br></pre></td></tr></table></figure>
<p>然后在提交offset的地方需要做一个判断，如果是<code>listener.batch.failedCnt &gt; 0</code>，执行<code>ssc.stop()</code>将程序杀掉，如果<code>listener.batch.failedCnt = 0</code>,则执行<code>commit offset</code>操作。</p>
<h4 id="限速和背压设置"><a href="#限速和背压设置" class="headerlink" title="限速和背压设置"></a>限速和背压设置</h4><h4 id="Exactly-once真的必要吗"><a href="#Exactly-once真的必要吗" class="headerlink" title="Exactly once真的必要吗"></a>Exactly once真的必要吗</h4><h4 id="Speculative机制有什么问题"><a href="#Speculative机制有什么问题" class="headerlink" title="Speculative机制有什么问题"></a>Speculative机制有什么问题</h4>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://sjq597.github.io/2019/12/30/CentOS7-%E5%AE%89%E8%A3%85transmission-%E8%BF%9C%E7%A8%8B%E4%B8%8B%E8%BD%BD/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LittleQ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LittleQ">
      <meta itemprop="description" content="数据开发工程师的成长历程">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LittleQ">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2019/12/30/CentOS7-%E5%AE%89%E8%A3%85transmission-%E8%BF%9C%E7%A8%8B%E4%B8%8B%E8%BD%BD/" class="post-title-link" itemprop="url">CentOS7 安装transmission 远程下载</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-12-30 23:41:56" itemprop="dateCreated datePublished" datetime="2019-12-30T23:41:56+08:00">2019-12-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-10-07 14:54:54" itemprop="dateModified" datetime="2023-10-07T14:54:54+08:00">2023-10-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/" itemprop="url" rel="index"><span itemprop="name">开发环境</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>384</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>买的VPS三年了，一不小心忘了续费过期了，数据环境全给清空了，又得重新配置环境。因为有ipv6地址，所以想把上学那会儿的PT站用起来，重新装下<code>transmission</code>,这个装好了可以直接从网页上添加任务挂种，比较方便，安装过程如下 </p>
<h3 id="安装Transmission"><a href="#安装Transmission" class="headerlink" title="安装Transmission"></a>安装Transmission</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 安装源</span><br><span class="line">yum install epel-release</span><br><span class="line"># 直接安装相关的包</span><br><span class="line">yum install transmission-*</span><br><span class="line"># 启动服务创建配置文件</span><br><span class="line">service transmission-daemon start</span><br><span class="line"># 停止文件修改配置文件</span><br><span class="line">service transmission-daemon stop</span><br></pre></td></tr></table></figure>
<p>修改配置文件<code>/var/lib/transmission/.config/transmission-daemon/settings.json</code>,需要改动的几个地方如下:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&quot;download-dir&quot;: &quot;/root/pt&quot;,</span><br><span class="line">&quot;incomplete-dir&quot;: &quot;/root/pt&quot;,</span><br><span class="line">&quot;rpc-authentication-required&quot;: true,</span><br><span class="line">&quot;rpc-port&quot;: 12345,</span><br><span class="line">&quot;rpc-enabled&quot;: true,</span><br><span class="line">&quot;rpc-password&quot;: &quot;the fuck password&quot;,</span><br><span class="line">&quot;rpc-username&quot;: &quot;zhangsan&quot;,</span><br><span class="line">&quot;rpc-whitelist&quot;: &quot;0.0.0.0&quot;,</span><br><span class="line">&quot;rpc-whitelist-enabled&quot;: false,</span><br></pre></td></tr></table></figure>
<p><strong>NOTE:</strong> 下载的目录文件夹你得手动创建一下，我这里直接就在<code>pt</code>文件夹下面了,端口最好也改下，不要用默认的。</p>
<p>然后重启服务</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl start transmission-daemon.service</span><br></pre></td></tr></table></figure>

<p>最后网页验证一下,访问<code>http://123.4.5.6:12345/transmission/web/</code>,如果可以访问那就说明可以了。</p>
<h3 id="百度云盘"><a href="#百度云盘" class="headerlink" title="百度云盘"></a>百度云盘</h3><p>其实用PT下载挺快的，一般可以达到30Mb&#x2F;s这种速度，但是怎么把文件搞回来是个问题，直接在服务器上起一个python的httpServer也可以，但是直连非常的慢，还不稳定，所以我采取了一种比较简单的方案：把下载下来的文件同步到百度云盘，然后再通过百度云下载。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://sjq597.github.io/2019/06/23/%E6%9E%9A%E4%B8%BE%E7%B1%BB%E5%9E%8B%E5%85%A8%E5%AD%97%E6%AE%B5%E5%BA%8F%E5%88%97%E5%8C%96%E8%BD%ACJSON/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LittleQ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LittleQ">
      <meta itemprop="description" content="数据开发工程师的成长历程">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LittleQ">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2019/06/23/%E6%9E%9A%E4%B8%BE%E7%B1%BB%E5%9E%8B%E5%85%A8%E5%AD%97%E6%AE%B5%E5%BA%8F%E5%88%97%E5%8C%96%E8%BD%ACJSON/" class="post-title-link" itemprop="url">枚举类型全字段序列化转JSON</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-06-23 16:55:36" itemprop="dateCreated datePublished" datetime="2019-06-23T16:55:36+08:00">2019-06-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-10-07 14:54:54" itemprop="dateModified" datetime="2023-10-07T14:54:54+08:00">2023-10-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Java%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">Java笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>846</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>3 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>最近在构思做一个通用化的字典工具,其中有一个功能就是自动扫描枚举类，将枚举类序列化成一张表，对比更新到数据库中。但是在实际中使用发现，如果不做任何限制，直接用<code>fastjson</code>的<code>JSON.toJSONString(obj)</code> 方法，得到的只是枚举的名字，并没有得到一个全字段的json串。即<code>SUCCESS(0, &quot;成功&quot;)</code>得到的将是<code>SUCCESS</code>这个字符串</p>
<p>fastjson版本:1.2.56</p>
<h4 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h4><ol>
<li>重写覆盖枚举类的toString() 方法</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">@Getter</span><br><span class="line">@AllArgsConstructor</span><br><span class="line">public enum EnumTest &#123;</span><br><span class="line">    SUCCESS(0, &quot;成功&quot;),</span><br><span class="line">    FAIL(-1, &quot;失败&quot;);</span><br><span class="line"></span><br><span class="line">    private int code;</span><br><span class="line">    private String msg;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public String toString() &#123;</span><br><span class="line">        return &quot;&#123;\n&quot; +</span><br><span class="line">                &quot;  \&quot;code\&quot;: &quot; + getCode() + &quot;,\n&quot; +</span><br><span class="line">                &quot;  \&quot;msg\&quot;: &quot; + getMsg() + &quot;\n&quot; +</span><br><span class="line">                &quot;&#125;&quot;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样的话，如果直接用<code>EnumTest.SUCCESS.toString()</code>就可以得到想要的结果，但是如果用<code>JSON.toJSONString(EnumTest.SUCCESS)</code>得到的仍然是<code>SUCCESS</code>。这个比较直白简单，但是不支持<code>fastjson</code>的方法,就是手动控制了枚举的<code>toString</code>输出内容，但是也有一个不好的问题就是，新增字段或者修改字段，还得改<code>toString</code>方法，万一忘了改，那可能会发生一些莫名其妙的Bug,而且还不易察觉,所以不推荐。<br>**NOTE:**注解是用了<code>lombok</code>包里面的一些方法</p>
<ol start="2">
<li>自定义SerializeConfig</li>
</ol>
<p>其实仔细看<code>JSON.toJSONString()</code>方法，有一些其他的重载方法提供了一些其他的参数，其中</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public static String toJSONString(Object object, SerializeConfig config, SerializerFeature... features) &#123;</span><br><span class="line">        return toJSONString(object, config, (SerializeFilter) null, features);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>这个里面有一个自定义序列化的配置参<br>使用如下:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SerializeConfig config = new SerializeConfig();</span><br><span class="line">config.configEnumAsJavaBean(EnumTest.class);</span><br><span class="line">System.out.println(JSON.toJSONString(EnumTest.SUCCESS, config));</span><br></pre></td></tr></table></figure>
<p>我们对比下几个的输出结果:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">System.out.println(&quot;1:&quot; + EnumTest.SUCCESS.toString());</span><br><span class="line">System.out.println(&quot;2:&quot; + JSON.toJSONString(EnumTest.SUCCESS));</span><br><span class="line"></span><br><span class="line">SerializeConfig config = new SerializeConfig();</span><br><span class="line">config.configEnumAsJavaBean(EnumTest.class);</span><br><span class="line">System.out.println(&quot;3:&quot; + JSON.toJSONString(EnumTest.SUCCESS, config));</span><br></pre></td></tr></table></figure>
<p>结果如下:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1:&#123;</span><br><span class="line">  &quot;code&quot;: 0,</span><br><span class="line">  &quot;msg&quot;: 成功</span><br><span class="line">&#125;</span><br><span class="line">2:&quot;SUCCESS&quot;</span><br><span class="line">3:&#123;&quot;code&quot;:0,&quot;msg&quot;:&quot;成功&quot;&#125;</span><br></pre></td></tr></table></figure>
<p>通过这种方式，可以比较灵活自由的达到我们想要的序列化效果，而没有破坏掉其他的一些引用到枚举类的地方，因为如果直接重载了枚举本身的<code>toString()</code>方法，会产生一些不可预知的错误。</p>
<h4 id="枚举嵌套"><a href="#枚举嵌套" class="headerlink" title="枚举嵌套"></a>枚举嵌套</h4><p>对于简单的枚举，这种应该没有啥问题，如果枚举出现了嵌套呢?我们写个例子测试一下,再申明一个<code>EnumTest2</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">// 枚举定义</span><br><span class="line">@Getter</span><br><span class="line">@AllArgsConstructor</span><br><span class="line">public enum EnumTest2 &#123;</span><br><span class="line">    SUCCESS(0, &quot;成功&quot;, EnumTest.SUCCESS),</span><br><span class="line">    FAIL(-1, &quot;失败&quot;, EnumTest.FAIL);</span><br><span class="line"></span><br><span class="line">    private int code;</span><br><span class="line">    private String msg;</span><br><span class="line">    private EnumTest enumTest;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 自定义序列化配置</span><br><span class="line">SerializeConfig config = new SerializeConfig();</span><br><span class="line">config.configEnumAsJavaBean(EnumTest2.class);</span><br><span class="line">System.out.println(JSON.toJSONString(EnumTest2.SUCCESS, config));</span><br><span class="line"></span><br><span class="line">// 输出</span><br><span class="line">&#123;&quot;code&quot;:0,&quot;enumTest&quot;:&quot;SUCCESS&quot;,&quot;msg&quot;:&quot;成功&quot;&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到<code>EnumTest2</code>本身序列化没问题，但是他的<code>enumTest</code>属性没有按照我们想要的方式来，需要改一些:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// 这个地方改一下</span><br><span class="line">config.configEnumAsJavaBean(EnumTest.class, EnumTest2.class);</span><br><span class="line">// 输出结果</span><br><span class="line">&#123;&quot;code&quot;:0,&quot;enumTest&quot;:&#123;&quot;code&quot;:0,&quot;msg&quot;:&quot;成功&quot;&#125;,&quot;msg&quot;:&quot;成功&quot;&#125;</span><br></pre></td></tr></table></figure>

<h4 id="枚举转字典"><a href="#枚举转字典" class="headerlink" title="枚举转字典"></a>枚举转字典</h4><p>其实上面的基本是为了搞清楚枚举的序列化问题，主要目的其实还是为了我们的字典如何同步。因为并不是所有的枚举都需要入库，所以我们需要实现一个注解，当有这个注解的枚举，那么我们会把他同步到字典中。当然还有一个问题就是上面探讨的，如果一个枚举他嵌套了其他的枚举，我们还需要把他所引用的枚举都配置到自定义序列化的配置里，所以实现如下:</p>
<h5 id="同步注解"><a href="#同步注解" class="headerlink" title="同步注解"></a>同步注解</h5>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://sjq597.github.io/2019/02/22/IllegalAccessError-HBaseZeroCopyByteString/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LittleQ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LittleQ">
      <meta itemprop="description" content="数据开发工程师的成长历程">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LittleQ">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2019/02/22/IllegalAccessError-HBaseZeroCopyByteString/" class="post-title-link" itemprop="url">IllegalAccessError HBaseZeroCopyByteString</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-02-22 19:32:09" itemprop="dateCreated datePublished" datetime="2019-02-22T19:32:09+08:00">2019-02-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-10-07 14:54:54" itemprop="dateModified" datetime="2023-10-07T14:54:54+08:00">2023-10-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E6%9E%B6%E6%9E%84/" itemprop="url" rel="index"><span itemprop="name">数据架构</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>1.1k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>4 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>最近有个Flink实时作业写HBase的任务发现丢数据了，Flink平台和HBase运维也无法定位到具体的问题，也没有任何异常日志。没办法只能通过把HBase数据导出到离线Hadoop集群来分析。<br>一开始怀疑MQ没有采集到日志，后来通过把Kafka日志拉取到HDFS查询发现数据是有的，那问题就只可能是在计算过程中丢失了。万幸实时采集的数据都有落HDFS，所以想离线分析一波，首先让运维<br>给HBase打了一个快照，然后给了个MR代码让我自己解析数据结构。</p>
<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>其实代码很简单，就是解析Cell把值解析出来然后写到HDFS路径上,需要用到的包也不多,pom.xml文件如下:<br>&#96;&#96;结构。</p>
<h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><p>其实代码很简单，就是解析Cell把值解析出来然后写到HDFS路径上,需要用到的包也不多,pom.xml文件如下:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>slf4j-api<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>slf4j-log4j12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hbase.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-protocol<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hbase.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hbase.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-server<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hbase.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-mapreduce-client-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>fastjson<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.54<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>具体的版本根据你的集群而定，然后就是解析程序了:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HBase2HDFSApp</span> &#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="type">Logger</span> <span class="variable">LOG</span> <span class="operator">=</span> LoggerFactory.getLogger(HBase2HDFSApp.class);</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *      * 需要传入的参数：快照名字，解析之后输出路径，快照输入路径，临时路径</span></span><br><span class="line"><span class="comment">     *      * <span class="doctag">@param</span> args</span></span><br><span class="line"><span class="comment">     *      * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="keyword">if</span> (args == <span class="literal">null</span>) &#123;</span><br><span class="line">            System.err.println(<span class="string">&quot;Parameter Errors ! Usage : &lt;snapshot_name&gt; &lt;output_path&gt; &lt;input_path&gt; &lt;tmp_output_path&gt;&quot;</span>);</span><br><span class="line">            System.exit(-<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">String</span> <span class="variable">snapShotName</span> <span class="operator">=</span> args[<span class="number">0</span>];</span><br><span class="line">        <span class="type">Path</span> <span class="variable">outputPath</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]);</span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> HBaseConfiguration.create();</span><br><span class="line">        configuration.set(<span class="string">&quot;hbase.rootdir&quot;</span>, <span class="string">&quot;hdfs://&quot;</span> + args[<span class="number">2</span>]);</span><br><span class="line">        configuration.set(<span class="string">&quot;mapreduce.job.queuename&quot;</span>, <span class="string">&quot;xxx&quot;</span>);</span><br><span class="line">        configuration.set(<span class="string">&quot;hadoop.tmp.dir&quot;</span>, <span class="string">&quot;xxxx&quot;</span>);</span><br><span class="line">        <span class="type">String</span> <span class="variable">jobName</span> <span class="operator">=</span> HBase2HDFSApp.class.getSimpleName();</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(configuration, jobName);</span><br><span class="line">        job.setJarByClass(HBase2HDFSApp.class);</span><br><span class="line">        LOG.info(<span class="string">&quot;start to init&quot;</span>);</span><br><span class="line">        TableMapReduceUtil.initTableSnapshotMapperJob(snapShotName,</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">Scan</span>(),</span><br><span class="line">                HBase2HDFSMapper.class,</span><br><span class="line">                Text.class,</span><br><span class="line">                NullWritable.class,</span><br><span class="line">                job, <span class="literal">true</span>, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">3</span>]));</span><br><span class="line">        LOG.info(<span class="string">&quot;init success&quot;</span>);</span><br><span class="line">        outputPath.getFileSystem(configuration).delete(outputPath, <span class="literal">true</span>);</span><br><span class="line">        FileOutputFormat.setOutputPath(job, outputPath);</span><br><span class="line">        job.setOutputFormatClass(TextOutputFormat.class);</span><br><span class="line">        job.setNumReduceTasks(<span class="number">0</span>);<span class="comment">//没有reduce</span></span><br><span class="line">        job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">HBase2HDFSMapper</span> <span class="keyword">extends</span> <span class="title class_">TableMapper</span>&lt;Text, NullWritable&gt; &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(ImmutableBytesWritable key, Result rs, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            <span class="type">byte</span>[] keyBytes = key.get();</span><br><span class="line">            <span class="type">JSONObject</span> <span class="variable">value</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JSONObject</span>();</span><br><span class="line">            <span class="type">String</span> <span class="variable">rk</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>(keyBytes);</span><br><span class="line">            List&lt;Cell&gt; list = rs.listCells();</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; list.size(); i++) &#123;</span><br><span class="line">                <span class="type">Cell</span> <span class="variable">cell</span> <span class="operator">=</span> list.get(i);</span><br><span class="line">                value.put(<span class="keyword">new</span> <span class="title class_">String</span>(CellUtil.cloneQualifier(cell)), <span class="keyword">new</span> <span class="title class_">String</span>(CellUtil.cloneValue(cell)));</span><br><span class="line">            &#125;</span><br><span class="line">            context.write(<span class="keyword">new</span> <span class="title class_">Text</span>(rk + <span class="string">&quot;\t&quot;</span> + value.toJSONString()), NullWritable.get());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>**NOTE:**需要注意的是<code>&lt;output_path&gt;和&lt;tmp_output_path&gt;</code>根目录要一致,然后就是不能使<code>&lt;input_path&gt;</code>的子目录.<br>编译打包之后提交运行，注意打包需要用到<code>assembly</code>插件,对应的<code>pom.xml</code>配置为:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;plugin&gt;</span><br><span class="line">    &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;2.6&lt;/version&gt;</span><br><span class="line">    &lt;configuration&gt;</span><br><span class="line">        &lt;descriptorRefs&gt;</span><br><span class="line">            &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;</span><br><span class="line">        &lt;/descriptorRefs&gt;</span><br><span class="line">    &lt;/configuration&gt;</span><br><span class="line">    &lt;executions&gt;</span><br><span class="line">        &lt;execution&gt;</span><br><span class="line">            &lt;id&gt;make-assembly&lt;/id&gt; &lt;!-- this is used for inheritance merges --&gt;</span><br><span class="line">            &lt;phase&gt;package&lt;/phase&gt; &lt;!-- bind to the packaging phase --&gt;</span><br><span class="line">            &lt;goals&gt;</span><br><span class="line">                &lt;goal&gt;single&lt;/goal&gt;</span><br><span class="line">            &lt;/goals&gt;</span><br><span class="line">        &lt;/execution&gt;</span><br><span class="line">    &lt;/executions&gt;</span><br><span class="line">&lt;/plugin&gt;`配置为:</span><br></pre></td></tr></table></figure>
<p>然后打包之后运行:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar ./target/xxx-1.0.0-SNAPSHOT-jar-with-dependencies.jar com.xxx.HBase2HDFSApp \</span><br><span class="line">&lt;snapshot_name&gt; \</span><br><span class="line">&lt;output_path&gt; \</span><br><span class="line">&lt;input_path&gt; \</span><br><span class="line">&lt;tmp-output_path&gt;</span><br></pre></td></tr></table></figure>
<p>然后就出现了一个经典的错误:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Caused by: java.lang.IllegalAccessError: class com.google.protobuf.HBaseZeroCopyByteString cannot access its superclass com.google.protobuf.LiteralByteString</span><br><span class="line">        at java.lang.ClassLoader.defineClass1(Native Method)</span><br><span class="line">        at java.lang.ClassLoader.defineClass(ClassLoader.java:763)</span><br><span class="line">        at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)</span><br><span class="line">        xxxx</span><br></pre></td></tr></table></figure>

<h1 id="问题原因"><a href="#问题原因" class="headerlink" title="问题原因"></a>问题原因</h1><p>google了一下,找到这个问题的解决方法,详细见链接: <a target="_blank" rel="noopener" href="http://www.voidcn.com/article/p-hhmhpejc-bh.html">http://www.voidcn.com/article/p-hhmhpejc-bh.html</a>. 大概就是引入了一个优化措施导致的,<br>这个问题的发生是由于优化了<a target="_blank" rel="noopener" href="https://issues.apache.org/jira/browse/HBASE-9867">HBASE-9867</a>引起的，无意间引进了一个依赖类加载器。它影响使用-libjars参数和使用 fat jar两种模式的job.<br>fat jar模式Hadoop的一个特殊功能：可以读取操作目录中&#x2F;lib目录下包含的所有库的JAR文件，把运行job依赖的jar放在jar中的lib目录下。</p>
<p>解决方式也比较简单:</p>
<ol>
<li>把缺的这个包拷贝到hadoop lib目录</li>
<li>环境变量中导入这个缺失的包</li>
</ol>
<p>由于我是临时跑一次，而且hadoop环境是公用的，直接破坏了不好，就采用的临时方案.首先定位到<code>com.google.protobuf.HBaseZeroCopyByteString</code>位于<code>hive-server</code>包中，具体对应的jar包是</p>
<blockquote>
<p>hbase-protocol-0.98.21-hadoop2-xxxx.jar</p>
</blockquote>
<p>具体的版本看你们公司集群编译之后对应的包版本即可,然后调整运行命令为:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_CLASSPATH=xxxx/hbase-protocol-0.98.21-hadoop2-xxx.jar</span><br><span class="line">hadoop jar ./target/xxx-1.0.0-SNAPSHOT-jar-with-dependencies.jar com.xxx.HBase2HDFSApp \</span><br><span class="line">&lt;snapshot_name&gt; \</span><br><span class="line">&lt;output_path&gt; \</span><br><span class="line">&lt;input_path&gt; \</span><br><span class="line">&lt;tmp-output_path&gt;</span><br></pre></td></tr></table></figure>
<p>然后运行就行了，大工告成。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://sjq597.github.io/2018/10/13/%E4%B8%83%E7%89%9B%E6%B5%8B%E8%AF%95%E5%9F%9F%E5%90%8D%E5%9B%9E%E6%94%B6%E8%BF%81%E7%A7%BB%E5%8D%9A%E5%AE%A2%E5%9B%BE%E5%BA%8A%E5%88%B0%E8%85%BE%E8%AE%AF%E4%BA%91/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LittleQ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LittleQ">
      <meta itemprop="description" content="数据开发工程师的成长历程">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LittleQ">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2018/10/13/%E4%B8%83%E7%89%9B%E6%B5%8B%E8%AF%95%E5%9F%9F%E5%90%8D%E5%9B%9E%E6%94%B6%E8%BF%81%E7%A7%BB%E5%8D%9A%E5%AE%A2%E5%9B%BE%E5%BA%8A%E5%88%B0%E8%85%BE%E8%AE%AF%E4%BA%91/" class="post-title-link" itemprop="url">七牛测试域名回收迁移博客图床到腾讯云</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2018-10-13 14:07:45" itemprop="dateCreated datePublished" datetime="2018-10-13T14:07:45+08:00">2018-10-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-10-07 14:54:54" itemprop="dateModified" datetime="2023-10-07T14:54:54+08:00">2023-10-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/" itemprop="url" rel="index"><span itemprop="name">博客搭建</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>1.7k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>6 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="七牛图床"><a href="#七牛图床" class="headerlink" title="七牛图床"></a>七牛图床</h1><p>最近发现博客里面用的七牛的免费图床全部过期了，之前也收到了七牛发的测试域名回收通知，当时以为域名过期了，再申请续一下就行，结果发现是直接都回收，啥都没有了，心中真是一万头草泥马。<br>之前工作比较忙也就忘了，最近登录博客一看，图片全部GG了, 博客搭建最近发现博客里面用的七牛的免费图床全部过期了，所以周末在家花时间就折腾了下迁移方案,记录一下.</p>
<h1 id="方案调研"><a href="#方案调研" class="headerlink" title="方案调研"></a>方案调研</h1><p>其实最初写博客的初衷也只是为了记录写自己日常工作中学到的一些东西，方便日后查阅。另外一个其实也有赠人玫瑰的想法,记录下工作中碰到的一些棘手的问题，方便同行交流。所以其实访问量不大，对图片的需求也不大，但是有时候博客里有必须得放一两张图。<br>所以最初在网上调研的时候，基本是看有哪些免费好用的图用的图床,当时看七牛的评价挺好的，一个月有10G的免费流量，一般人根本用不到那么多，而且方案也比较成熟，各种工具啥的都有，就用七牛了。所以现在不让用了，就调研了下其他的方案,网上有推荐其他免费图床的，反正我是真不敢用了。还有一些推荐阿里OSS的，不过据说收费比较复杂，用之前先好好研究下收费公式，因为我只有腾讯的vps,所以就只关注了腾讯的方案，腾讯和阿里OSS对应的服务叫COS,并且收费方式也很良心，大家可以去这里看下:<a target="_blank" rel="noopener" href="https://buy.cloud.tencent.com/price/cos/calculator">定价对象存储 COS</a><br><img src="https://blog-1254094716.cos.ap-chengdu.myqcloud.com/%E7%89%9B%E6%B5%8B%E8%AF%95%E5%9F%9F%E5%90%8D%E5%9B%9E%E6%94%B6%E8%BF%81%E7%A7%BB%E5%8D%9A%E5%AE%A2%E5%9B%BE%E5%BA%8A%E5%88%B0%E8%85%BE%E8%AE%AF%E4%BA%9101.png" alt="COS计费规则截图"><br>所以看这个图，基本上你可以不用花钱，流量肯定够你用了.</p>
<h1 id="图片备份"><a href="#图片备份" class="headerlink" title="图片备份"></a>图片备份</h1><p>这里有个很坑的地方就是，如果你的测试域名过期，你上传到七牛云的文件你是没办法直接访问的,你会发现点击预览和下载都是没有反,你会发现点击预览和下载都是没有反应的，这是因为你上传生成的域名链接已经被回收了，是无法通过网页URL来访问的,只能通过其他接口来操作,主要有下面几个步骤:</p>
<h2 id="新建存储空间"><a href="#新建存储空间" class="headerlink" title="新建存储空间"></a>新建存储空间</h2><p>之前那个存储空间里面上传的文件已经没有办法访问了，但是可以创建一个新的存储空间，通过其他接口把文件都转移到新的存储空间，这样就可以访问那些失效的文件了，比如可以建一个新的存储空间叫<code>backup</code></p>
<h2 id="下载开发工具"><a href="#下载开发工具" class="headerlink" title="下载开发工具"></a>下载开发工具</h2><p><a target="_blank" rel="noopener" href="https://developer.qiniu.com/kodo/tools/1302/qshell">命令行工具(qshell)</a>,这个工具提供了很多接口，下载下来解压就能直接用，根据的操作系统选择对应的就行，详细的可以看下载界面的链接,如果只用一次，也不用去设置什么环境变量了，直接开始搞</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 我的是mac,所以用的是下面这个，具体的取决于你的系统</span><br><span class="line">sudo chmod +x qshell-darwin-x64</span><br><span class="line">ln -s qshell-darwin-x64 qshell</span><br><span class="line"># AK/SK 需要去 个人中心-&gt;密钥管理 看下你自己的</span><br><span class="line">./qshell account &lt;AK&gt; &lt;SK&gt;</span><br><span class="line"># 把过期存储空间所有文件列表保存到文件</span><br><span class="line">./qshell listbucket &lt;old存储空间&gt; list.txt</span><br><span class="line"># 切割出文件名</span><br><span class="line">cat list.txt | awk -F &#x27;\t&#x27; &#x27;&#123;print $1&#125;&#x27; &gt; list_final.txt</span><br><span class="line"># 把过期的文件列表搬迁到新的存储空间,我这里会出现让输入一个确认字符串，照着输入就行</span><br><span class="line">./qshell batchcopy &lt;old存储空间&gt; backup list_final.txt</span><br></pre></td></tr></table></figure>
<p>  然后就可以在网页上的新的存储空间看到之前那些无法查看的文件了.</p>
<h2 id="批量下载到本地"><a href="#批量下载到本地" class="headerlink" title="批量下载到本地"></a>批量下载到本地</h2><p>qshell提供了qdownload可以批量下载文件，不过官网给出的api文档特别标注了，这个接口默认是要收费的:<strong>配置【该功能默认需要计费，如果希望享受10G的免费流量，请自行设置cdn_domain参数，如不设置，需支付源站流量费用，无法减免！！！】</strong>,先看下用法:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">qshell qdownload [&lt;ThreadCount&gt;] &lt;LocalDownloadConfig&gt;</span><br></pre></td></tr></table></figure>
<p>  第一个下载线程数参数是个可选参数，可以不用管,主要是需要写个配置文件，并且记住，得配置下<code>cdn_domain</code>这个参数，新建一个配置文件<code>batch_download.conf</code>:</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;dest_dir&quot;   :   &quot;/xxx/xxx/Downloads/qiniu&quot;,</span><br><span class="line">    &quot;bucket&quot;     :   &quot;backup&quot;,</span><br><span class="line">    &quot;prefix&quot;     :   &quot;&quot;,</span><br><span class="line">    &quot;suffixes&quot;   :   &quot;&quot;,</span><br><span class="line">    &quot;cdn_domain&quot; :   &quot;http://pgiolcvny.bkt.clouddn.com&quot;,</span><br><span class="line">    &quot;referer&quot;    :   &quot;&quot;,</span><br><span class="line">    &quot;log_file&quot;   :   &quot;download.log&quot;,</span><br><span class="line">    &quot;log_level&quot;  :   &quot;info&quot;,</span><br><span class="line">    &quot;log_rotate&quot; :   1,</span><br><span class="line">    &quot;log_stdout&quot; :   false</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>  <strong>备注:</strong><code>cdn_domain</code>这个就是你的<code>backup</code>这个存储空间的对外访问域名,每个参数的具体含义及使用事项在这里可以看到<a target="_blank" rel="noopener" href="https://github.com/qiniu/qshell/blob/master/docs/qdownload.md">qdownload参数解释</a>,配置好之后就可以执行:<br>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./qshell qdownload batch_download.conf</span><br></pre></td></tr></table></figure><br>  终端中就可以看到日志，然后在<code>dest_dir</code>中就可以看到你要下载的文件了。</p>
<h2 id="上传到腾讯COS"><a href="#上传到腾讯COS" class="headerlink" title="上传到腾讯COS"></a>上传到腾讯COS</h2><p>我们把所有的文件下载下来之后，然后还需要把文件上传到COS，这样图片才可以作为资源被外部访问,如果你之前没有使用过对象存储服务，还需要先创建一个存储桶，记住权限要设置成对外可读(不然别人也访问不了),然后把这些文件上传到这个存储桶里边，这个在网页上就可以直接操作，可以批量把刚才下载的都上传了。</p>
<h2 id="批量替换"><a href="#批量替换" class="headerlink" title="批量替换"></a>批量替换</h2><p>然后就只剩一步了，我们现在可以通过腾讯的COS来作为我们的图床服务，所以如果你写的新的博客，可以直接用新的地址，但是你之前写的那些博客，都是七牛的域名，所以需要把博客的原始文件里面的图片链接全部替换成腾讯COS的域名，老的域名可以看你的博客文件，我的是:<code>http://7xn9y9.com1.z0.glb.clouddn.com</code>,然后新的域名可以直接在腾讯云控制台，点开一张你上传过的图片查看,我的是:<code>https://blog-1254094716.cos.ap-chengdu.myqcloud.com</code>.具体的文件名因为都是一样的编码方式，所以只用替换域名就行，这里可以用<code>sed</code>命令来批量操作:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd source/_post</span><br><span class="line"></span><br><span class="line"># Linux用户</span><br><span class="line">sed -i &#x27;s#(http://7xn9y9.com1.z0.glb.clouddn.com#(https://blog-1254094716.cos.ap-chengdu.myqcloud.com#g&#x27; *.md</span><br><span class="line"></span><br><span class="line"># Mac用户</span><br><span class="line">sed -i -e &#x27;s#(http://7xn9y9.com1.z0.glb.clouddn.com#(https://blog-1254094716.cos.ap-chengdu.myqcloud.com#g&#x27; *.md</span><br><span class="line">rm *.md-e</span><br></pre></td></tr></table></figure>
<p>**NOTE:**之所以替换的链接带上<code>(</code>是为了防止误伤,比如这边文章里就有七牛的域名链接地址,但是图片链接在MarkDown写法里都是放在括号里的,所以记得这么替换就行。</p>
<p>然后你可以去访问下你的博客，找一篇有图的，应该是可以访问的。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://sjq597.github.io/2018/08/22/Kafka%E6%91%B8%E9%B1%BC%E7%B3%BB%E5%88%9701-%E7%99%BE%E4%B8%87QPS%E5%90%9E%E5%90%90%E9%87%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LittleQ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LittleQ">
      <meta itemprop="description" content="数据开发工程师的成长历程">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LittleQ">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2018/08/22/Kafka%E6%91%B8%E9%B1%BC%E7%B3%BB%E5%88%9701-%E7%99%BE%E4%B8%87QPS%E5%90%9E%E5%90%90%E9%87%8F/" class="post-title-link" itemprop="url">Kafka摸鱼系列01-百万QPS吞吐量</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2018-08-22 00:27:21" itemprop="dateCreated datePublished" datetime="2018-08-22T00:27:21+08:00">2018-08-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-10-07 14:54:54" itemprop="dateModified" datetime="2023-10-07T14:54:54+08:00">2023-10-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Kafka/" itemprop="url" rel="index"><span itemprop="name">Kafka</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>1.4k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>5 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>最近打算写一下关于<code>Kafka</code>系列的文章，在整个数据体系中,<code>Kafka</code>扮演着一个非常重要的角色-<strong>数据总线</strong>.作为一个数据开发工程师,在数据的采集&#x2F;存储&#x2F;流计算&#x2F;ETL&#x2F;数据仓库&#x2F;数据应用这几个方面,<code>Kafka</code>起到的作用是非常大的,甚至会影响到其他组建或者环节的技术选型.<br>在很久以前,在<code>Kafka</code>还没那么成熟的时候,很多的数据基础组件在设计之初并没有考虑到数据接收&#x2F;数据输出解藕,以及数据容灾式持久化,往往都需要配合第三方或者额外开发其他的组件去保证数据的吞吐量以及可靠性,例如<code>sqoop</code>,<code>canal</code>.不过这个都不是本文的重点,本文的重点在于:为何现在很多公司都把<code>Kafka</code>作为整个数据链路的<strong>数据总线</strong>,这里很关键的一点是–<strong>吞吐量</strong>.</p>
<h2 id="常用MQ介绍"><a href="#常用MQ介绍" class="headerlink" title="常用MQ介绍"></a>常用MQ介绍</h2><p>这里我不会对其他MQ做过多的介绍，但是市面上的主流MQ也必须有个大概的了解，之所以流行开来也是有其独特的优势,<code>Kafka</code>也不例外,先放一张<a target="_blank" rel="noopener" href="https://yq.aliyun.com/articles/62834">阿里云栖社区</a>做的MQ对比图:<br><img src="https://blog-1254094716.cos.ap-chengdu.myqcloud.com/Kafka%E6%91%B8%E9%B1%BC%E7%B3%BB%E5%88%9701-%E7%99%BE%E4%B8%87QPS%E5%90%9E%E5%90%90%E9%87%8F01.png" alt="业界主流MQ对比"><br>主要看下吞吐量这个地方,除了和<code>RocketMQ</code>领先的不多，基本上是碾压其他的<code>MQ</code>.一般性能好的<code>MQ</code>吞度量能达到几十万这个量级就非常厉害了,但是可以看到用机械磁盘的<code>Kafka</code>单机<code>TPS</code>差不多可以到200w了,那么对于一个集群而言,几百万的<code>TPS</code>完全不在话下.</p>
<p><strong>这就引出了本文要讨论的一个重要问题:<code>Kafka</code>为什么这么快,吞吐量为何这么惊人?</strong></p>
<h2 id="Kafka吞吐量之谜"><a href="#Kafka吞吐量之谜" class="headerlink" title="Kafka吞吐量之谜"></a>Kafka吞吐量之谜</h2><p>这个问题要想回答的好或者说回到的全面，其实并不简单.一个系统设计的这么好,往往是多方面综合考虑的结果,当然在剖析<code>Kafka</code>性能之前，先大概说一下实际使用情况下<code>Kafka</code>性能是否真的如网上说的那么优秀．因为目前BU内部的Kafka是由自己维护,所以规模不是很大,但也支撑了整个BU所有的日常数据业务.</p>
<h3 id="线上规模"><a href="#线上规模" class="headerlink" title="线上规模"></a>线上规模</h3><p>集群| 版本 | CPU | 内存 | 磁盘 | 网卡   | brokers数量<br>—–|—–|——|——|——–|——–<br>1| 0.8.2.1 | 32核| 64G |2T  |    10Gbps | 5<br>2| 1.0.0 | 32核| 64G |2T  |    10Gbps | 5<br>3| 0.10.2.1 | 32核| 128G |2T  |    1Gbps | 3</p>
<p>目前主要数据在<code>0.8.2.1</code>,这个集群使用了大概有3年了,一直很稳定,也承载了几乎所有的数据,可以注意到两个上面的机器其实对配置要求不是很高,但是对磁盘(机械磁盘,T级别)和网卡(万兆)要求会稍微高一些.从这里可以看出,<code>Kafka</code>的性能瓶颈一般在磁盘和网卡.对CPU和内存的要求其实不是很高.实际使用也确实是,最开始本来也是千兆网卡,后来发现<code>brokers</code>节点容易出现网卡被打满,性能上不去的情况.还有就是磁盘有时候会不够用．</p>
<p>下面来说一一介绍一下,为啥<code>Kafka</code>吞吐量能做到这么高.</p>
<h3 id="存储设计"><a href="#存储设计" class="headerlink" title="存储设计"></a>存储设计</h3><p>单机写入能到百万级别,并且还是廉价的磁盘.要知道读&#x2F;写机械磁盘,寻址操作是一个很耗时的IO操作,这也就是为什么现在的DB或者像ES这样的存储系统都慢慢换成SSD了．<br>那<code>Kafka</code>是怎么做的呢,它在设计之初的一个目标就是:</p>
<blockquote>
<p>以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间复杂度的访问性能.</p>
</blockquote>
<p>所以<code>Kafka</code>一开始便被设计成一个日志系统,消息只能<code>append</code>,这使得<code>Kafka</code>非常适合用来作为数据总线,所有的数据根据到来的顺序被顺序序列化到文件末尾,然后消费者也是按顺序消费.<br>实际测试使用中,顺序读写机械磁盘有时候比随机读写内存的吞吐量还要好.当然这个还归功于CPU的工作方式,在加载数据的时候,CPU会预测，连带读取一整块数据,下次读取如果命中,就直接从内存中读,也不用再去加载.</p>
<h3 id="Producer"><a href="#Producer" class="headerlink" title="Producer"></a>Producer</h3><p>消息的写入主要由<code>producer</code>完成,首先简单说下<code>Kafka</code>的消息结构,每一个主题<code>topic</code>的消息有多个<code>partition</code>组成,每个<code>partition</code>都会有<code>leader</code>,<code>follower</code>.这里强调一下,不管是<code>producer</code>写数据还是<code>consumer</code>读数据,都是跟<code>leader</code>打交到,<code>follower</code>只负责从对应的<code>leader</code>同步数据.<code>follower</code>和<code>leader</code>一起构成了这个<code>partition</code>的<code>ISR</code>(同步复制队列),如果<code>follower</code>复制没有跟上,会被从<code>ISR</code>中剔除.所以只有当<code>leader</code>节点挂掉的时候,<code>ISR</code>中的<code>follower</code>节点才有可能备胎转正,数据的读写有新的<code>leader</code>节点负责.<br>所以说到写数据,就必须要说到<code>Kafka</code>的<code>Ack</code>机制.有时候性能和可靠性本身就是矛盾的,<code>Kafka</code>发送数据光快还不行,还得保证可靠性.<br>Ack机制</p>
<ol>
<li>0:表示producer无需等待leader的确认，</li>
<li>1:代表需要leader确认写入它的本地log并立即确认，</li>
<li>-1:代表所有的备份都完成后确认</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://sjq597.github.io/2018/08/11/%E7%BA%BF%E4%B8%8AJstorm%E8%B0%83%E4%BC%98%E5%8F%8A%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LittleQ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LittleQ">
      <meta itemprop="description" content="数据开发工程师的成长历程">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LittleQ">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2018/08/11/%E7%BA%BF%E4%B8%8AJstorm%E8%B0%83%E4%BC%98%E5%8F%8A%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/" class="post-title-link" itemprop="url">线上Jstorm调优及问题排查</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2018-08-11 17:11:27" itemprop="dateCreated datePublished" datetime="2018-08-11T17:11:27+08:00">2018-08-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-10-07 14:54:54" itemprop="dateModified" datetime="2023-10-07T14:54:54+08:00">2023-10-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E6%9E%B6%E6%9E%84/" itemprop="url" rel="index"><span itemprop="name">数据架构</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.3k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>8 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="问题产生"><a href="#问题产生" class="headerlink" title="问题产生"></a>问题产生</h3><p>之前有一段时间<code>beta jstorm</code>集群打日志老是把磁盘都占满了,一开始懒得管,每次都是把<code>dump</code>堆栈文件直接删掉了.但是只是缓解了问题,后面磁盘在一段时间之后还是会别打满,后来有空排查了下问题,简单记录一下.<br>首先关于如何排查线上<code>Jstorm</code>作业问题这个,其实<code>Jstorm UI</code>也提供了线上的界面,可以查看作业执行日志以及<code>dump</code>堆内存,但是想看实时日志的话还是得到对应机器上查看,另外有些时候还得查看<code>Worker</code>日志才能比较好定位问题,这里用一个线上的实际问题来看下一般怎么排查问题.</p>
<h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>问题是这样的,<code>Jstorm</code>集群的机器最近经常磁盘报警,线上查看发现是<code>Worker</code>生成了很多<code>*.hprof</code>文件.这里简单说下,<code>Jstorm</code>集群的一个具体的<code>Worker</code>进程在发生<code>OOM</code>的时候会生成dump文件,也就是<code>*.hprof</code>文件,具体参数就是我们常说的<code>-XX:+HeapDumpOnOutOfMemoryError</code>.所以如果程序写的有问题某些参数设置的不对,或者数据量太大导致<code>OOM</code>的话,会不停的<code>dump</code>内存生成文件,直到磁盘被耗光.</p>
<h3 id="问题排查"><a href="#问题排查" class="headerlink" title="问题排查"></a>问题排查</h3><p>首先既然是磁盘被耗光了,那先看下磁盘上哪个<code>Worker</code>日志文件占用的磁盘空间最多,定位到具体的<code>Worker</code>之后,我们可以看下jvm运行信息:<br><img src="https://blog-1254094716.cos.ap-chengdu.myqcloud.com/%E7%BA%BF%E4%B8%8AJstorm%E8%B0%83%E4%BC%98%E5%8F%8A%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5001.jpg" alt="Jstorm Worker Jvm运行统计"><br>可以看到<code>Perm</code>区已经<code>100%</code>了，其他几个区使用率很低,<code>FullGC</code>一直在增加,这个时候基本上就可以判断是<code>Perm</code>区的问题了，我们再确认下<code>Worker</code>的启动参数,直接<code>ps -axu | grep 32502</code>即可:<br><img src="https://blog-1254094716.cos.ap-chengdu.myqcloud.com/%E7%BA%BF%E4%B8%8AJstorm%E8%B0%83%E4%BC%98%E5%8F%8A%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5002.jpg" alt="Work启参数"><br>注意下红色标出来的部分<code>-XX:PermSize=33554432 -XX:MaxPermSize=33554432</code>,算一下基本就是<code>32M</code>这么大.方法区一般存的就是类的信息,这说明加载了太多的<code>Class</code>,可以用<code>jmap -histo:live 32502</code>看下，会发现确实有好多<code>xxxClass</code>的实例,说明确实是．最后我还看了对应的代码文件，发现也的确是用到了很多的的包，并且还是写在<code>static</code>代码块做初始化的．所以最后我改了下启动参数,具体为修改<code>storm.yaml</code>文件:</p>
<blockquote>
</blockquote>
<p>nimbus.childopts: “ -Xms1g -Xmx1g -Xmn500m -XX:PermSize&#x3D;50m -XX:SurvivorRatio&#x3D;4 -XX:MaxTenuringThreshold&#x3D;15 -XX:+UseConcMarkSweepGC -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction&#x3D;70 -XX:CMSFullGCsBeforeCompaction&#x3D;5 -XX:+HeapDumpOnOutOfMemoryError -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles&#x3D;5 -XX:GCLogFileSize&#x3D;100M -XX:+UseCMSCompactAtFullCollection -XX:CMSMaxAbortablePrecleanTime&#x3D;5000 “<br>**PS:**当然不是说你改了就可以生效了,你需要先把对应的<code>Worker</code>进程干掉,我一般是直接<code>kill &lt;pid&gt;</code>,因为只要不是强制杀掉,Jstorm会在其他节点重启这个<code>Worker</code>,所以不会丢数据啥的,就直接杀掉了,然后是重启<code>Supervisor</code>进程,然后那些新提交的启动的<code>Worker</code>就会用新的参数启动,所有的就这么简单了,完事儿收工睡觉.</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>其实在使用了这么久的<code>Jstorm</code>后，也想总结一下个人对<code>Jstorm</code>的看法,或者说大一点,对实时计算框架的一点看法,因为我本人也没有用过原生的<code>Storm</code>,所以这两者的框架优缺点我就不展开了.<br>首先说下<code>Jstorm</code>,也是目前我们采用的流处理框架,目前业务日志实时处理都是用的<code>Jstorm</code>,处理之后的日志会存到<code>ES/Hbase/Redis</code>这几个地方,上层会有应用去实时使用这些数据.因为日志是不可变更数据,所以<code>Jstorm</code>的异步+compent(并发度) 可以很好的提高吞度量而不用去考虑数据的处理顺序而去而外考虑同步态.并且日志数据的要求会低一些,就是允许丢失部分数据,所以在写ES的时候,也是bulk+异步的方式写,也不至于存储过程卡住.<br>然后要说的是<code>Spark Streaming</code>,这个也是流处理框架,不过之前更多的是被称作<code>Micro Batch</code>框架,现在好像也支持真正意义上的流式处理了,细节就不多说了,没有实际用过.<code>Spark Streaming</code>在部门使用场景主要是为了处理<code>db binlog</code>数据.前面也说了<code>Jstorm</code>是异步的,意思就是不同的<code>bolt</code>之间异步,同一<code>bolt</code>不同<code>task</code>之间也是异步,但是有一些数据处理场景需要考虑到处理顺序以及同步,如果都是异步处理,那么数据的最终顺序可能会和读取的顺序不一致,所以这个时候就需要采用<code>Async+Sync</code>结合的方式处理.对应<code>Spark Streaming</code>来说就是<code>batch</code>与<code>batch</code>之前同步,<code>batch</code>内部<code>job</code>之间,<code>task</code>之间异步.<br>这样的好处也比较明显,<code>batch</code>之间类似于有一层屏障来控制顺序,但是<code>batch</code>内部的<code>task</code>并发处理数据，吞吐量也不会受同步影响太高.缺点也比较哦明显,需要等待前面的<code>batch</code>完成,所以<code>latency</code>必定比不上真正的流式处理框架<code>Jstorm</code>.<br>最后要说的一个是<code>Flink</code>,最初开始了解这个东西是在2016年,所以<code>Flink</code>诞生的时间最晚,因此在设计上也更加的先进(如果不是那也就没有必要重复设计).这个东西目前部门内部没有用,但是公司是主推新的作业尽量用<code>Flink</code>来开发.后面也打算把计算全部迁移到<code>Flink</code>,不过工程量可能有些大.就我调研和使用场景来说.这个东西确实要比<code>Jstorm</code>好,说几个我个人的感觉:</p>
<ol>
<li>Flink支持Scala开发,目前Jstorm还是用Java开发,做过数据开发的人就应该知道,Scala在数据处理方面确实要比Java写起来开发效率高很多,Java其优势还是在Web后端这块.</li>
<li>调试.这个开发过你就知道了,可能当初<code>Jstorm</code>的设计人员并没有考虑到这个问题,虽然<code>Jstorm</code>也可以在本地调试,但是需要你写不一样的代码;而<code>Flink</code>以及<code>Spark Streaming</code>这两者代码基本不需要怎么改就可以在本地调试,开发上更人性化.</li>
<li>设计理念,毕竟是后出来的,肯定设计的初衷也是为了解决当前框架无法解决,或者说无法优雅解决的问题.所以会吸收精华部分,摒弃糟粕,设计理念也会更加先进.尤其是一些关键点:吞吐,延迟,反压这些问题.</li>
</ol>
<p>另外还有个人建议不使用<code>Jstorm</code>的理由,从去年发布<code>Jstorm 2.2/2.4</code>之后,差不多有一年都没有更新了,社区活跃度不高,<code>Issue</code>基本上没人管了.不过有些东西比较有价值的,<code>flue-core</code>,这个东西其实是<code>Storm</code>的一个插件,当让也可以在<code>Jstorm</code>里面用,简单来说就是可以写一个<code>yaml</code>配置文件去定义一个作业,这样就不用再编译提交<code>jar</code>包来启动作业了．那么我们可以定义或者提前编写一些通用的公共<code>bolt</code>组件,做一个平台来开发<code>Jstorm</code>作业,可以做到页面化开发而不用手写<code>Java</code>代码.</p>
<p>最后说一下自己在使用这些大数据的开源组件的一些见解,其实用过很多组件之后会发现,他们之间会有一些共同的设计理念,举个<code>flume</code>的例子:<br><img src="https://blog-1254094716.cos.ap-chengdu.myqcloud.com/%E7%BA%BF%E4%B8%8AJstorm%E8%B0%83%E4%BC%98%E5%8F%8A%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5003.png" alt="flume架构"><br>这里有三个比较重要的组件:<code>source,channel,sink</code>.我不知道是不是<code>flume</code>首创的这个,但是从组件的开源时间上来看应该是.很巧的是<code>flink</code>里面也是这么个结构,所以确实可以说这个结构真的是一个优秀的设计思想.尤其是<code>channel</code>这个思想,其实很多的开源组件在设计的时候并没有引入这种设计,比如<code>Canal</code>,所以只能自己去实现具体的数据存储功能,其实这个是不利于推广的,不能开箱即用.正因为<code>Channel</code>的存在,所以<code>source/sink</code>可以实现复用及自由组合,比较灵活,扩展性很强,但是需要有一个<code>Channel</code>支撑,<code>Kafka</code>就是这么个存在,所以<code>Kafka</code>的那几个哥们后来出来创业了,围绕<code>Kafka</code>创建了<a target="_blank" rel="noopener" href="https://www.confluent.io/">Confluent</a>,这个里面围绕<code>Kafka</code>创建了各种不同的<code>source/sink</code>,基本涵盖了所有的数据源以及存储源,这种通过一个<code>Channel</code>来缓冲以及解藕不同的逻辑单元,在数据处理领域来说应该是一种非常值得借鉴的思想.在建设基础数据体系或者一个系统的时候,可以多考虑这种结构.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://sjq597.github.io/2018/05/24/Linux%E8%BF%90%E7%BB%B4%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%A4%87%E5%BF%98%E5%BD%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LittleQ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LittleQ">
      <meta itemprop="description" content="数据开发工程师的成长历程">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LittleQ">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2018/05/24/Linux%E8%BF%90%E7%BB%B4%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%A4%87%E5%BF%98%E5%BD%95/" class="post-title-link" itemprop="url">Linux运维常用命令备忘录</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2018-05-24 14:47:04" itemprop="dateCreated datePublished" datetime="2018-05-24T14:47:04+08:00">2018-05-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-10-07 14:54:54" itemprop="dateModified" datetime="2023-10-07T14:54:54+08:00">2023-10-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Linux%E4%BD%BF%E7%94%A8/" itemprop="url" rel="index"><span itemprop="name">Linux使用</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>1.3k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>5 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>作为一个后端开发,尤其是数据开发,我们很多的服务都是以进程的方式运行在后台.例如Jstorm&#x2F;Kafka&#x2F;ElasticSearch等等,线上报警处理也是一个必备技能了,更多的可能是一些磁盘,内存,CPU指标之类的,有些命令不常用可能会忘记,做个记录方便查找.</p>
<h3 id="磁盘"><a href="#磁盘" class="headerlink" title="磁盘"></a>磁盘</h3><p>这个应该是最常见的,磁盘报警是家常便饭了.</p>
<h4 id="df-lh"><a href="#df-lh" class="headerlink" title="df -lh"></a>df -lh</h4><p>查看系统磁盘占用情况,一般磁盘报警了可以先用这个命令看下大概是哪个盘出问题了,找到占用比较大的磁盘有时候需要配合其他命令:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 到具体的目录下执行</span><br><span class="line"># 1.快速方法</span><br><span class="line">du -sh</span><br><span class="line"># 2.推荐方法(-x 可以过滤掉和一开始文件系统不一样的文件/文件系统)</span><br><span class="line">du -h --max-depth=1</span><br></pre></td></tr></table></figure>
<p>这里不推荐第一种方式是因为效率问题，如果碰上是根<code>/</code>目录满了,基本上统计不出来,如果为了快，想配合排序定位问题,还可以配合sort函数使用</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 倒序排(一般占用大基本上就是看G,很少会到T,毕竟磁盘没那么大,也有例外)</span><br><span class="line">du -h --max-depth=1 | grep [TG] |sort -nr | head</span><br></pre></td></tr></table></figure>

<h4 id="find"><a href="#find" class="headerlink" title="find"></a>find</h4><p>这个命令紧跟在上一个命令后面,就是因为很多时候我们需要批量删除满足某些条件的文件,但这些文件可能并不是简单的在一个文件夹下面,类型一样.可能分散在某个目录下面的多级目录,并且类型也很多:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 根据文件类型来删,比如日志文件 *.log</span><br><span class="line">find . -name &#x27;*.xxx&#x27; -delete</span><br><span class="line"># or</span><br><span class="line">find . -name &#x27;*.xxx&#x27; -exec sudo rm -f &#123;&#125; \;</span><br><span class="line"># 根据时间 -mtime:内容时间 -ctime:状态修改</span><br><span class="line">find . -mtime +10 -a -ctime +10 -delete</span><br><span class="line"># 根据文件大小 &gt;100k &lt;500M</span><br><span class="line">find . -size +100k +size -500M -delete</span><br></pre></td></tr></table></figure>
<p>**NOTE:**find命令<code>-a</code>:与,<code>-or</code>:或,<code>not</code>:否.另外使用删除请慎重,可以先用<code>-print</code>打印一下看看是否满足要求,不然删了不该删的后果可能很严重.</p>
<h4 id="swap"><a href="#swap" class="headerlink" title="swap"></a>swap</h4><p>有时候磁盘满了可能是swap设置的太大,占用的swap又无法释放(内存就算有很大空闲,swap已经使用的可能也不会释放),导致磁盘一直报警,处理这个要稍微麻烦一点儿.首先看下磁盘占用比较大的几个程序,或者说看下有没有比较重要的服务占用着缓存,有的话重启下,先把重要的程序占用的swap释放掉,然后关闭缓存,开启缓存:<br>看一次实际线上问题:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ free -m</span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:          11855        2366        9146         157         341        9144</span><br><span class="line">Swap:          4095        2600        1495</span><br></pre></td></tr></table></figure>
<p>可以看到内存有很多空闲,但是swap占用了2.6G无法释放，然后统计下是哪些进程在占用着swap:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$ for i in $(sudo ls /proc | grep &quot;^[0-9]&quot; | awk &#x27;$0&gt;100&#x27;); do sudo awk &#x27;/Swap:/&#123;a=a+$2&#125;END&#123;print &#x27;&quot;$i&quot;&#x27;,a/1024&quot;M&quot;&#125;&#x27; /proc/$i/smaps;done| sort -k2nr | head</span><br><span class="line">awk: fatal: cannot open file `/proc/10612/smaps&#x27; for reading (No such file or directory)</span><br><span class="line">awk: fatal: cannot open file `/proc/10613/smaps&#x27; for reading (No such file or directory)</span><br><span class="line">awk: fatal: cannot open file `/proc/10614/smaps&#x27; for reading (No such file or directory)</span><br><span class="line">awk: fatal: cannot open file `/proc/10615/smaps&#x27; for reading (No such file or directory)</span><br><span class="line">awk: fatal: cannot open file `/proc/10616/smaps&#x27; for reading (No such file or directory)</span><br><span class="line">20211 466.664M</span><br><span class="line">23994 215.438M</span><br><span class="line">9339 208.672M</span><br><span class="line">9334 167.766M</span><br><span class="line">9340 152.559M</span><br><span class="line">9338 132.375M</span><br><span class="line">20293 88.9883M</span><br><span class="line">9342 86.918M</span><br><span class="line">9335 84.4492M</span><br><span class="line">4323 76.8984M</span><br></pre></td></tr></table></figure>
<p>可以看到进程号和对应的缓存占用大小(如果不想看到错误信息,可以grep -v “No such”过滤掉),看下具体的有没有比较重要的,如果想看具体的程序,后面可以用awk切割出pid,然后配合<code>ps -p xxx</code>看下具体的进程是不是重要的，手动重启下.然后就是比较关键的两个操作:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 关闭所有缓存</span><br><span class="line">swapoff -a</span><br><span class="line"># 开启所有缓存</span><br><span class="line">swapon -a</span><br></pre></td></tr></table></figure>
<p>这样swap就全部被清空了.</p>
<h4 id="lsof"><a href="#lsof" class="headerlink" title="lsof"></a>lsof</h4><p>这个命令可能一般人用的比较少,这个主要是看文件句柄的,有时候一个文件很大，我们直接删了,但是会发现磁盘空间并没有释放.这个时候一般就是还有进程占用着这个文件句柄,所以你可能在目录里面看没有什么文件,但是磁盘就是被占用了.可以这么排查:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 查看文件为删除状态的文件</span><br><span class="line">lsof | grep deleted</span><br></pre></td></tr></table></figure>
<p>这个命令里面就可以看到是哪个进程持有这个文件的句柄,比如像tomcat,有时候日志打太多了,但是你直接删掉,磁盘根本不会减少,这个时候你可以重启下tomcat,就会发现文件占用的空间又回来了.</p>
<h3 id="cpu-mem"><a href="#cpu-mem" class="headerlink" title="cpu&#x2F;mem"></a>cpu&#x2F;mem</h3><p>这两个一般都是用top命令来看,所以放在一起说了.一般top之后可以看到进程的实时信息,top有一些常用参数命令</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">c top显示带具体进程信息</span><br><span class="line">M 按mem占用排序</span><br><span class="line">P 按cpu占用排序</span><br><span class="line"># 具体线程信息</span><br><span class="line">top -H -p &#123;pid&#125;</span><br></pre></td></tr></table></figure>
<p>具体的进程问题，可能得用具体的方法,这里就不做展开了.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://sjq597.github.io/2018/05/22/%E5%A6%82%E4%BD%95%E8%87%AA%E4%B8%8B%E8%80%8C%E4%B8%8A%E8%AE%BE%E8%AE%A1%E5%BC%80%E5%8F%91%E4%B8%80%E4%B8%AA%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%E7%B3%BB%E7%BB%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LittleQ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LittleQ">
      <meta itemprop="description" content="数据开发工程师的成长历程">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LittleQ">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2018/05/22/%E5%A6%82%E4%BD%95%E8%87%AA%E4%B8%8B%E8%80%8C%E4%B8%8A%E8%AE%BE%E8%AE%A1%E5%BC%80%E5%8F%91%E4%B8%80%E4%B8%AA%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%E7%B3%BB%E7%BB%9F/" class="post-title-link" itemprop="url">如何自下而上设计开发一个大数据准实时同步系统</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2018-05-22 22:28:09" itemprop="dateCreated datePublished" datetime="2018-05-22T22:28:09+08:00">2018-05-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-10-07 14:54:54" itemprop="dateModified" datetime="2023-10-07T14:54:54+08:00">2023-10-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E6%9E%B6%E6%9E%84/" itemprop="url" rel="index"><span itemprop="name">数据架构</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.7k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>13 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>最近项目基本上进入尾声了，也有时间来整理下最近做的这个项目.因为主要就一个人在做,所以周期比较长,整个系统涉及到的开源数据框架比较多,所以感觉还是有不少价值的,当然这个里面也有很多的坑,只有做过才能体会到,后面我会慢慢展开.</p>
<h1 id="项目背景"><a href="#项目背景" class="headerlink" title="项目背景"></a>项目背景</h1><p>主要是两个公司合并了,哪两家就不说了,反正是行业Top1,Top2.后来打算成立新公司,所以数据需要整合.其实在一开始合并之后,数据就有陆陆续续的整合,不过这种整合方式效率比较低,整个链路很长,涉及到很多部门,圈绕的比较大.具体的流程大概说下:</p>
<ol>
<li>首先数据在我们的数据仓库ETL跑完之后,会有一个下游作业把数据拷贝到一个公共hadoop队列里面(Hadoop权限这块比较差,由于支付的数据要求较高,在防火墙内,不可能共享Hive数据仓库所在目录的数据,所以只能采取这种方式共享数据);</li>
<li>然后由专门和对方公司数据部门对接的人来把我们拷贝到指定队列的数据从hadoop上下载下来,上传公有云服务器(其实就是FTP服务器);</li>
<li>然后对方公司的数据组有专门的人从公有云把数据下载到他们的Hadoop客户机上,然后把数据上传到他们的Hadoop集群,然后数据才能达到基本能用的状态.</li>
</ol>
<p>**PS:**由于Hive本身作为离线数据仓库,数据延迟为T+1,然后数据再到他们那，延迟就变成了T+2,并且整个过程涉及到的部门比较多.数据不出问题还好,一旦出了问题,得找到每个环节的负责人,然后定位问题出现的环节,总之是很麻烦.</p>
<p>所以上面的老大也觉得这种方式使用数据非常的麻烦,成本太大,关键是数据的时效性也不满足要求,所以就想做实时数据流同步,整合两边的数据仓库.当然数据仓库只是实时数据流的一个用途之一,也会有其他数据使用场景,比如实时计算之类的.</p>
<h1 id="设计方案"><a href="#设计方案" class="headerlink" title="设计方案"></a>设计方案</h1><p>一般而言,一个完整的数据体系结构都比较复杂,我这里就大概说下整体架构:</p>
<p><img src="https://blog-1254094716.cos.ap-chengdu.myqcloud.com/%E5%A6%82%E4%BD%95%E8%87%AA%E4%B8%8B%E8%80%8C%E4%B8%8A%E8%AE%BE%E8%AE%A1%E5%BC%80%E5%8F%91%E4%B8%80%E4%B8%AA%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%E7%B3%BB%E7%BB%9F001.png" alt="数据体系结构图"><br>如果觉得图片太小看不清可以在新标签中打开查看大图.我会从下而上简单说下这个架构里面都有些什么东西:</p>
<h2 id="数据采集"><a href="#数据采集" class="headerlink" title="数据采集"></a>数据采集</h2><p>数据系统的第一步,数据采集.这部分数据主要分为两大类,DB数据以及业务日志</p>
<h3 id="Database"><a href="#Database" class="headerlink" title="Database"></a>Database</h3><p>第一类就是比较主要的,业务数据库数据采集,目前基本上都是用的mysql数据库,所以采集方案比较大众化都是采用阿里的<a target="_blank" rel="noopener" href="https://github.com/alibaba/canal">Canal</a>,当然一般可能不能直接拿来用，需要你根据公司的技术架构做一些二次开发,因为一般公司内部会对MySQL做一些架构来给业务提供高可用的特性.数据采集之后会封装成自定义的<code>Kafka Message</code>,为了方便区分,topic命名方式可以有一个统一规则,例如binlog_{db实例架构类型}_{db实例名},这样能比较方便知道某个db实例的binlog数据特性以及排查问题.这里需要注意的就是往Kafka上写数据的时候,Kafka的分区策略要注意下，一个参考建议就是可以采用(Schema,Table)作为PartitionKey.这样可以保证同一个表的数据是顺序存放在同一个分区的,这样后续的一些程序处理可以保证数据的顺序性.<br>**NOTE:**封装的KafkaMessage可以根据业务来,如果想简单起见,可以把Canal的RowChange消息整个封装进去.</p>
<h3 id="Tomcat-Log"><a href="#Tomcat-Log" class="headerlink" title="Tomcat Log"></a>Tomcat Log</h3><p>这部分数据原则上来说,并没有Database数据重要,因为我们建的大部分数据表,模型都是基于业务的ER关系表来的.但是日志数据可以做很多其他的事情,数据挖掘里面也有很大的用途,还有的主要就是业务辅助用,后面会讲一些使用场景.业务日志采集采取的方案比较多,有采用入侵式埋点的,但是现在的普遍做法应该还是非入侵式采集,因为日志采集事实上对业务而言是一个非必须的功能,但是线上业务首先要保证性能和可靠性不受其他无关影响.<br>采集业务日志一般采用的就是flume tail功能,对指定日志目录下面的文件执行类似Linux:<code>tail -f</code>命令不断滚动采集新产生的日志.这个里面也有很多的坑,目前最新的flume好像支持直接采集一个目录,这样就不用自己写tail插件去采集日志了.这部分日志采集之后也是放在Kafka集群,同样的也需要自己封装成定义的KafaMessage.建议是需要保留日志的文件名以及机器名,所以分区策略是用这两个key就可以了.<br>**NOTE:**一般大一点儿的公司,线上的业务系统都会有appId这种东西,所以建议如果有这个信息也封装到KafkaMessage消息里面.</p>
<h2 id="数据计算"><a href="#数据计算" class="headerlink" title="数据计算"></a>数据计算</h2><p>数据存储之后,就是数据的计算了,Kafka毕竟只能存一段时间,过期就会删除,所以这些消息会落地到其他的存储系统,不同类型的数据有不同的落地场景，相同的数据也可能有不同的落地场景,下面一个一个说下这些应用及落地场景:</p>
<h3 id="Binlog-Hive"><a href="#Binlog-Hive" class="headerlink" title="Binlog-&gt;Hive"></a>Binlog-&gt;Hive</h3><p>Database的binlog数据采集到Kafka之后,最大的一个用途就是作为数据仓库的ods层源数据.由于离线数据仓库一般延迟要求不高，基本上默认就是T+1,所以我们不用事实计算这部分数据,反而是吞吐量是个很重要的指标.所以这里可以考虑的就是Spark Streaming这个框架,微批处理,可以在延迟和吞吐量之间做一个很好的平衡.<br>当然如果你没有Spark集群,也可以用Flume消费Kafka消息写到本地(据说直接写HDFS性能不是很好，没有测试过),然后隔一段时间put到hdfs上.关于写的策略,因为每天的binlog是增量数据,所以你需要一个字段作为binlog的分区依据,可以在将Canal消息封装KafkaMessage的时候加上一个binlog的执行时间.<br>**关键点:**这个过程其实坑还是挺多的,Binlog一般并发比较大,你要保证数据可以准确去重,不会取到错误的数据.</p>
<h3 id="Binlog-ElasticSearch"><a href="#Binlog-ElasticSearch" class="headerlink" title="Binlog-&gt;ElasticSearch"></a>Binlog-&gt;ElasticSearch</h3><p>这个需求和Hive那个很像，但是又有一些区别.Hive不支持单行记录更新(据说貌似新版本的支持了,没去详细了解过),ElasticSearch简单来说就是作为Database里面的表的一个镜像.因为MySQL的单表数据量在超过5000w的时候性能会变得非常差,所以业务上为了性能考虑,都会对表按月或者其他规则做分表.所以一般像运营,开发,测试在查询数据的时候非常的不方便.而ElasticSearch本身就是作为索引系统而存在的,非常适合有大量的查询场景.<br>这个因为并不是同步到离线数据仓库里面,所以对数据的延迟要求会高一些,这个时候Spark Streaming就不太合适,那么可不可以使用Jstorm这种流式处理框架呢?答案是不行,原因也很简单,JStorm这种流处理框架是<code>at least once</code>语义,也就是能保证数据至少被处理一次(当然好像后面的版本是准备实现还是已经实现了<code>exactly only once</code>,反正我们自己用的并没有内置支持),并且还有一个很重要的原因就是:JStorm无法保证数据的顺序,一个拓扑里面的每个bolt会有多个task,数据如果是按随机分发的话,不同的task处理速度是没办法预估的,这就可能导致先产生的binlog变更记录有可能后写入到ElasticSearch,就容易出现数据不一致的问题.所以这种情况下异步流处理框架是没有办法处理这种问题的,所以在技术选型上我们可以选像<code>Spark Streaming</code>这种顺序批处理(但是也有条件限制,就是每次只能有一个batch在执行,队列设置成FIFO).<br>这里简单说下我们的技术方案:首先从Kafka消费Binlog,清洗出每个表的<code>Primary Key</code>,封装成自定义的Kafka Message写回到Kafka,然后再从Kafka去消费这种消息,拿到<code>Primary Key</code>,然后查询对应的Database,这样每次都是拿到的最新的记录,然后更新ElasticSearch,这样就不用担心数据变更记录顺序不一致的问题,因为每次拿到的都是最新的.至于历史数据问题也比较简单,直接把当前表里面的记录清洗出Key写到Kafka,后面作业不用改,自然就会消费到这些消息,整体架构如下:</p>
<p><img src="https://blog-1254094716.cos.ap-chengdu.myqcloud.com/%E5%A6%82%E4%BD%95%E8%87%AA%E4%B8%8B%E8%80%8C%E4%B8%8A%E8%AE%BE%E8%AE%A1%E5%BC%80%E5%8F%91%E4%B8%80%E4%B8%AA%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%87%86%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%E7%B3%BB%E7%BB%9F002.png" alt="Binlog-ElasticSearch"></p>
<p>**优化点:**其实这个项目后期还是有一些优化点的,目前为了简单起见是采取的中转了一次,并且反查Database的方案,这样可以不用考虑数据的顺序,正确性问题,因为反查拿到的数据永远是当前时间点的正确数据.但是也会有一个问题,就是服务部署的机器无法做到动态扩容,需要有指定Database的连接权限,公司的Database都是采用的ip白名单方式,需要提前申请权限.其实如果Kafka保证Binlog的数据正确性,那么下游完全不用再反查Database，直接按变更记录查询就行了,唯一需要担心的就是数据初始化和已有数据同步作业同时跑的一个顺序问题.</p>
<h3 id="Tomcat-Log-Redis-Hbase-ElasticSearch-Hadoop"><a href="#Tomcat-Log-Redis-Hbase-ElasticSearch-Hadoop" class="headerlink" title="Tomcat Log-&gt;Redis&#x2F;Hbase&#x2F;ElasticSearch&#x2F;Hadoop"></a>Tomcat Log-&gt;Redis&#x2F;Hbase&#x2F;ElasticSearch&#x2F;Hadoop</h3><p>这一步相信会有很多的应用场景,基本就涵盖了几乎所有的日志使用场景了,分别大致说一下几个场景吧.</p>
<h4 id="Trace系统"><a href="#Trace系统" class="headerlink" title="Trace系统"></a>Trace系统</h4><p>这个应该算是最终要,最有意义的一个东西:分布式式追踪系统.基本上一个稍微大一点儿的公司都会有自己的Trace系统,一方面是大公司的系统比较复杂,一件事情往往需要很多个系统互相配合才能完成;另外一个就是现在微服务比较火,都在提倡系统解藕,所以调用链会比较长.业界有名的就是Google 的Dapper,具体的实现有阿里的鹰眼(不开源),Twitter的Zipkin.当然这不是我们这里的主要内容,我们只关心如何应用,也就是在有traceId的情况下,这些日志能有哪些应用场景.有大概这么几个场景:</p>
<ol>
<li>服务异常排查: 这个就是用到的traceId,我们把这些日志通过流计算作业提取traceId,把日志按照qrtaceId存放,当某个服务出问题了,可以通过查询服务的调用链,分析具体的出问题在哪个环节.</li>
<li>用户行为&#x2F;订单流程分析: 这个的原理其实和上面的差不多,只不过现在不是看traceId,而是看userId&#x2F;orderNo.这个应用场景也很大,主要是发现异常数据,定位排查细节,一般我们会选取某个有问题的用户,查到他某个时间段的所有行为日志.上面这两个就比较适合存放在HBase中,至于为什么,了解HBase的特性的人应该就明白了.</li>
<li>运营分析: 一般对于有些系统,运营会关注系统的异常数据,在系统出现问题的时候,有时候运营需要查询到异常数据,然后批量做人工处理.我们也通过流计算提取所有的日志中的<code>Execption Log</code>,按应用名,系统,机器名,异常类型存放到ElasticSearch中.之所以放在ES中主要是因为可以安装ES-SQL插件,运营可以写SQL查询统计这些信息.当然也会有定时作业去汇总这些信息发邮件,按照系统给相关负责人发邮件.</li>
</ol>
<h4 id="Hive数据仓库"><a href="#Hive数据仓库" class="headerlink" title="Hive数据仓库"></a>Hive数据仓库</h4><p>虽然数据仓库主要是业务的DB数据,但是日志里面也含有非常多的信息,而且DB受限于业务和性能,不会把所有的东西都存在DB里面,但是日志就自由多了,可以输出很多有用的信息,比如记录用户的位置&#x2F;搜索&#x2F;页面浏览记录,再比如修改密码&#x2F;登录这些,往往DB里面只会记录成功的那条记录,中间很多失败的信息是只存在于日志里面的.所以这部分数据也会通过Streaming作业这个ETL过程并入到Hive数据仓库里面.PM也主要是分析用户行为日志来改进用户体验.</p>
<h4 id="统一查询"><a href="#统一查询" class="headerlink" title="统一查询"></a>统一查询</h4><p>这个说起来其实也不算一个单独的功能,上面的这几个其实说到底也是提供了统一查询的功能.这里要说的是一个统一入口问题,正常的开发线上排查问题,查看日志都是直接到对应的机器上查看的.但是当我们有实时日志采集系统之后,完全可以做到屏蔽机器这层概念,即通过我们的系统直接实时tail服务器上的日志,虽然会有延迟,但是在秒级别的话是可以忽略的.</p>
<h1 id="未完待续"><a href="#未完待续" class="headerlink" title="未完待续"></a>未完待续</h1>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://sjq597.github.io/2018/05/22/ShadowSocks-Haproxy%E4%B8%AD%E7%BB%A7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LittleQ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LittleQ">
      <meta itemprop="description" content="数据开发工程师的成长历程">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | LittleQ">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2018/05/22/ShadowSocks-Haproxy%E4%B8%AD%E7%BB%A7/" class="post-title-link" itemprop="url">ShadowSocks+Haproxy中继</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2018-05-22 20:24:11" itemprop="dateCreated datePublished" datetime="2018-05-22T20:24:11+08:00">2018-05-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-10-07 14:54:54" itemprop="dateModified" datetime="2023-10-07T14:54:54+08:00">2023-10-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Linux%E4%BD%BF%E7%94%A8/" itemprop="url" rel="index"><span itemprop="name">Linux使用</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>805</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>3 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>最近发现家里的网连我国外的服务器非常的慢,丢包已经基本上到了访问不了的地步了,所以搭的ss代理基本上只能在公司用.之前花几百快撸的腾讯云服务器放了好几个月都没管过了,正好拿来做中继代理.之前买了半年的阿里云服务器搞过，后来过期了没有续费了,这次撸了6年的应该够用了.</p>
<h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><p>其实就是运营商的国际出口比较堵,所以直接访问国外的服务器丢包严重，当然实测应该还有一个原因，应该是运营商主动干扰这些代理服务器.个人感觉后面的可能性要大一些,不过不管是哪种都不重要了,要实现低延迟链路，只能借助大厂的线路(阿里，腾讯),基本原理也很简单:</p>
<ul>
<li>直连方案:<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">local(A) --&gt; sserver(C)</span><br></pre></td></tr></table></figure></li>
<li>中继方案:<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">local(A) --&gt; aliyun/cloud tencent(B) --&gt; sserver(C)</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a>安装配置</h1><p>主要是在中继机器B上操作,sserver(C)不用做任何变更,首先登录我们的中继机器(B):</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install haproxy -y</span><br></pre></td></tr></table></figure>
<p>然后就是配置我们的机器了,编辑<code>sudo vim /etc/haproxy/haproxy.cfg</code>,直接改成下面这样:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">global</span><br><span class="line">    ulimit-n  51200</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line">    log     global</span><br><span class="line">    mode    tcp</span><br><span class="line">    option  dontlognull</span><br><span class="line">    timeout connect 5000</span><br><span class="line">    timeout client  50000</span><br><span class="line">    timeout server  50000</span><br><span class="line"></span><br><span class="line">frontend ss-in</span><br><span class="line">    bind *: &#123;B_local_listen_port&#125;</span><br><span class="line">    default_backend ss-out</span><br><span class="line"></span><br><span class="line">backend ss-out</span><br><span class="line">    server sserver_name &#123;sserver_ip&#125;:&#123;sserver_port&#125; maxconn 20480</span><br></pre></td></tr></table></figure>
<p>这里需要设置的几个地方为:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;B_local_listen_port&#125;:这个就是中继服务器监听外部请求的端口,为了你local改动小,这个端口可以设置和sserver(C)的端口一致</span><br><span class="line">&#123;sserver_ip&#125;:这个就很好理解了,就是你部署sserver的机器的ip,后面那个端口也是ss服务器的端口</span><br></pre></td></tr></table></figure>
<p>等这些都改完了，然后还需要做一件事,就是给你的中继服务器开安全组策略，阿里和腾讯的云主机基本上是一样的，开入站和出战规则即可,然后把设置好的安全组规则绑定到你的机器实例上.简单来说就是需要对<code>&#123;B_local_listen_port&#125;</code>开入站规则,对<code>&#123;sserver_port&#125;</code>开出战规则，如果你分不清觉得麻烦，就把这两个端口设置的一样,然后开一个端口的出站和入站规则即可.</p>
<h1 id="服务启用"><a href="#服务启用" class="headerlink" title="服务启用"></a>服务启用</h1><p>由于你改了安全组规则，所以需要重启你的服务器实例,重启好了之后,需要启动haproxy服务,不同的机器不一样，以我的腾讯云主机为例:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">systemctl start haproxy.service</span><br><span class="line"># 设置成开机启动(CentOS7)</span><br><span class="line">systemctl enable haproxy.service</span><br><span class="line"># 设置成开机启动(CentOS6,没测试过，网上查的)</span><br><span class="line">chkconfig –level 3 haproxy.service on</span><br></pre></td></tr></table></figure>
<p>启动服务之后可以检测一下服务是否开启了,直接用<code>ps</code>命令即可.</p>
<p>然后就是本地<code>local</code>机器,即<code>sslocal</code>的配置,因为我们上面配置的中继监听端口和<code>sserver</code>的端口一致,所以我们的<code>sslocal</code>只用改一个ip，端口不用改,ip由原来的<code>sserver ip</code>改为中继服务器的ip就行了.延迟由原来的300ms直接降为40ms,收工.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/15/">15</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2023</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">LittleQ</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">124k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">7:31</span>
  </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  






  





</body>
</html>
