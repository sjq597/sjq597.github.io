<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"sjq597.github.io","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.18.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="公司的日志一般会有专门的日志收集系统，但是上传到hdfs上目录太多，一般都是按机房，按小时分割日志文件的。路径类似于下面这样: 1234&#x2F;user&#x2F;xxx&#x2F;l-xxxx1.pay.cn1&#x2F;20160717&#x2F;log.20160717-18.gz&#x2F;user&#x2F;xxx&#x2F;l-xxxx1.pay.cn1&#x2F;20160717&#x2F;log.20160717-19.gz&#x2F;user&#x2F;xxx&#x2F;l-xxxx2.pay.cn1&#x2F;">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop Streaming收集日志">
<meta property="og:url" content="http://sjq597.github.io/2016/07/18/Hadoop-Streaming%E6%94%B6%E9%9B%86%E6%97%A5%E5%BF%97/index.html">
<meta property="og:site_name" content="LittleQ">
<meta property="og:description" content="公司的日志一般会有专门的日志收集系统，但是上传到hdfs上目录太多，一般都是按机房，按小时分割日志文件的。路径类似于下面这样: 1234&#x2F;user&#x2F;xxx&#x2F;l-xxxx1.pay.cn1&#x2F;20160717&#x2F;log.20160717-18.gz&#x2F;user&#x2F;xxx&#x2F;l-xxxx1.pay.cn1&#x2F;20160717&#x2F;log.20160717-19.gz&#x2F;user&#x2F;xxx&#x2F;l-xxxx2.pay.cn1&#x2F;">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2016-07-18T07:58:11.000Z">
<meta property="article:modified_time" content="2023-10-07T06:54:54.000Z">
<meta property="article:author" content="LittleQ">
<meta property="article:tag" content="Linux">
<meta property="article:tag" content="Hadoop">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://sjq597.github.io/2016/07/18/Hadoop-Streaming%E6%94%B6%E9%9B%86%E6%97%A5%E5%BF%97/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://sjq597.github.io/2016/07/18/Hadoop-Streaming%E6%94%B6%E9%9B%86%E6%97%A5%E5%BF%97/","path":"2016/07/18/Hadoop-Streaming收集日志/","title":"Hadoop Streaming收集日志"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Hadoop Streaming收集日志 | LittleQ</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">LittleQ</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">爱好：写代码</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop-Streaming"><span class="nav-number">1.</span> <span class="nav-text">Hadoop Streaming</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C"><span class="nav-number">2.</span> <span class="nav-text">常用操作</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">LittleQ</p>
  <div class="site-description" itemprop="description">数据开发工程师的成长历程</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">145</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">51</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://sjq597.github.io/2016/07/18/Hadoop-Streaming%E6%94%B6%E9%9B%86%E6%97%A5%E5%BF%97/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LittleQ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LittleQ">
      <meta itemprop="description" content="数据开发工程师的成长历程">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Hadoop Streaming收集日志 | LittleQ">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Hadoop Streaming收集日志
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2016-07-18 15:58:11" itemprop="dateCreated datePublished" datetime="2016-07-18T15:58:11+08:00">2016-07-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-10-07 14:54:54" itemprop="dateModified" datetime="2023-10-07T14:54:54+08:00">2023-10-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" itemprop="url" rel="index"><span itemprop="name">数据挖掘</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>公司的日志一般会有专门的日志收集系统，但是上传到hdfs上目录太多，一般都是按机房，按小时分割日志文件的。路径类似于下面这样:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/user/xxx/l-xxxx1.pay.cn1/20160717/log.20160717-18.gz</span><br><span class="line">/user/xxx/l-xxxx1.pay.cn1/20160717/log.20160717-19.gz</span><br><span class="line">/user/xxx/l-xxxx2.pay.cn1/20160717/log.20160717-18.gz</span><br><span class="line">/user/xxx/l-xxxx3.pay.cn1/20160717/log.20160717-19.gz</span><br></pre></td></tr></table></figure>
<p>即日志文件会按小时打包<code>log.20160717-xx.gz</code>,另外日志可能会标注机房<code>l-xxxx[1-9].pay.cn[1-9]</code>不同机器,这样会对应很多个目录，这样就无法通过在Hive里面建一个表指向一个固定的hdfs路径来分析日志数据。我们必须通过一个方法把这些日志转化到一个路径，然后把数据<code>load</code>到Hive表中，然后就可以对日志的数据做一些分析，或者使用了。</p>
<h3 id="Hadoop-Streaming"><a href="#Hadoop-Streaming" class="headerlink" title="Hadoop Streaming"></a>Hadoop Streaming</h3><p>这里使用到的是Hadoop原生的<code>Streaming</code>，毕竟我们的目的也不是很负复杂，就是一个数据收集汇总的过程，当然这中间也可以做一些简单的处理，例如过滤掉不需要的日志，毕竟日志不比MySQL里面的结构化数据，日志的量级一般都很大，都装到Hive表里面数据量大分析的时候也需要更多的计算资源，也更慢</p>
<p>由于服务器上的<code>hadoop</code>是2.2.0版本的，所以我这里使用的是<code>hadoop-streaming-2.2.0.jar</code>。主要使用<code>shell</code>,<code>python</code>简单介绍一下如何使用这个。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$HADOOP_HOME/bin/hadoop  jar $HADOOP_HOME/hadoop-streaming.jar \</span><br><span class="line">    -input myInputDirs \</span><br><span class="line">    -output myOutputDir \</span><br><span class="line">    -mapper /bin/cat \</span><br><span class="line">    -reducer /bin/wc</span><br></pre></td></tr></table></figure>
<p>上面是具体的在shell里面执行的时候参数的指定，这里最简单的用法就是执行输入目录或者输入文件，以我上面的例子为例，涉及到多个机房，日志还按小时分割打包，可以写成</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-input /user/xxx/l-xxxx*.pay.cn*/20160717/log.20160717-*.gz</span><br></pre></td></tr></table></figure>
<p>即路径可以使用通配符<code>*</code>指定,然后还要指定一个汇总日志输出路径:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-output /user/xxx/logs/xxxx/output/20160717/log_parse </span><br></pre></td></tr></table></figure>

<p>这里主要是想讲一下<code>mapper</code>和<code>reducer</code>文件的编写，采用python实现:<br>先看一下<code>mapper.py</code>文件的实现</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line"># coding=utf-8</span><br><span class="line"></span><br><span class="line">import re</span><br><span class="line">import sys</span><br><span class="line"></span><br><span class="line">reg_pattern = r&#x27;(\d+-\d+-\d+ \d+:\d+:\d+.\d+).*GwRouteBizImpl\s*-\s*(\w*)\&#123;(.*)\&#125;.*&#x27;</span><br><span class="line">re_gx = re.compile(reg_pattern)</span><br><span class="line"></span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    line = line.strip().replace(&#x27;\t&#x27;, &#x27; &#x27;).replace(&#x27;\r&#x27;, &#x27; &#x27;)</span><br><span class="line"></span><br><span class="line">    if re_gx.match(line):</span><br><span class="line">        print &#x27;%s&#x27; % re.sub(reg_pattern, r&#x27;\1\t\2\t\3&#x27;, line)</span><br></pre></td></tr></table></figure>
<p>这就是一个最简单的过滤日志，并简单做一些字段的提取，因为我们采用<code>\t</code>分割，所以需要把每一行的特殊字符去掉，然后用正则匹配满足格式的日志，如果不满足，这条日志就直接过滤掉了。<br>**注意:**使用Hadoop原生的<code>Streaming</code>程序，只能处理标准输入输出,另外如果对输入不做任何处理，可以直接使用系统自带的<code>/bin/cat</code>，不用单独写<code>mapper</code>或者<code>reducer</code>，当然你也可以使用python写一个,什么也不干，原样输出<code>reducer.py</code>:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    line = line.strip()</span><br><span class="line">    print &#x27;%s\t&#x27; % line</span><br></pre></td></tr></table></figure>

<p>具体使用就很简单了，在shell里面调用:</p>
<blockquote>
<p>sudo -u${HADOOP_USER} ${HADOOP_HOME}&#x2F;bin&#x2F;hadoop jar ${HADOOP_HOME}&#x2F;share&#x2F;hadoop&#x2F;tools&#x2F;lib&#x2F;hadoop-streaming-2.2.0.jar -D stream.non.zero.exit.is.failure&#x3D;false -mapper “python mapper.py” -reducer “python reducer.py” -input ${HADOOP_LOG_FILE} -output ${HADOOP_OUTPUT_DIR} -file reducer.py -file mapper.py</p>
</blockquote>
<p>**备注:**如果<code>mapper</code>,<code>reducer</code>不是使用系统的shell命令,那么就需要加上<code>-file</code>参数来把我们用其他程序写的代码分发到所有节点。另外还有一个地方需要注意，要确保<code>-output output_dir</code>路径不存在，你需要在调用之前调用删除命令:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo -u$&#123;HADOOP_USER&#125; $&#123;HADOOP_HOME&#125;/bin/hadoop fs -rm -r output_dir</span><br></pre></td></tr></table></figure>

<p>还有一些常用的参数设置:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-jobconf &lt;key&gt;=&lt;value&gt;</span><br></pre></td></tr></table></figure>
<p>例如:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-jobconf mapreduce.job.queue.name=xxx -jobconf mapreduce.job.name=xxx</span><br></pre></td></tr></table></figure>

<h3 id="常用操作"><a href="#常用操作" class="headerlink" title="常用操作"></a>常用操作</h3><p>对于日志这种，其实是多路输入，合并到一路输出，中间只是把一行内容变成一行内容，用特定字符分隔开来而已，所以并没有<code>reduce</code>过程，如果我们用了上面那个参数，最后会又有一个<code>reducer</code>，特别慢，关键是有可能内存不够，所以可以取消掉</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-jobconf mapred.reduce.tasks=0</span><br></pre></td></tr></table></figure>
<p>这样就不会有<code>reducer</code>了，会快很多。</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Linux/" rel="tag"># Linux</a>
              <a href="/tags/Hadoop/" rel="tag"># Hadoop</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2016/07/14/D3-js-%E7%AC%94%E8%AE%B002/" rel="prev" title="D3 js 笔记02">
                  <i class="fa fa-angle-left"></i> D3 js 笔记02
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2016/07/19/Ubuntu-16-04-Hadoop%E6%9C%AC%E5%9C%B0%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/" rel="next" title="Ubuntu 16.04 Hadoop本地安装配置">
                  Ubuntu 16.04 Hadoop本地安装配置 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2023</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">LittleQ</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  






  





</body>
</html>
